% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  10pt,
  letterpaper]{article}

\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
  \setmainfont[]{Charis SIL}
  \setmonofont[]{Monaco}
  \setmathfont[]{Monaco}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin = 1in]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{tabularx}
\usepackage{threeparttable}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{tipa}
\let\Oldtexttt\texttt
\renewcommand\texttt[1]{{\ttfamily\color{BrickRed}#1}}
\usepackage{authoraftertitle}
\usepackage{fancyhdr}
\pagestyle{fancy}
\rfoot{\copyright Matt Hunt Gardner}
\cfoot{\thepage}
\lhead{Doing LVC with \textit{R}: \MyTitle}
\rhead{}
\makeatletter
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Table}
\else
  \newcommand\figurename{Table}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[many]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
% Make links footnotes instead of hotlinks:
\DeclareRobustCommand{\href}[2]{#2\footnote{\url{#1}}}
\hypersetup{
  pdftitle={Mixed-Efects Logistic Regression Analysis: Part 3},
  pdfauthor={Matt Hunt Gardner},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Mixed-Efects Logistic Regression Analysis: Part 3}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{from
\href{https://lingmethodshub.github.io/content/R/lvc_r/}{Doing LVC with
\emph{R}}}
\author{Matt Hunt Gardner}
\date{3/11/23}

\begin{document}
\maketitle
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[frame hidden, borderline west={3pt}{0pt}{shadecolor}, boxrule=0pt, breakable, interior hidden, sharp corners, enhanced]}{\end{tcolorbox}}\fi

Before you proceed with this section, please make sure that you have
your data loaded and modified based on the code
\href{https://lingmethodshub.github.io/content/R/lvc_r/050_lvcr.html}{here}
and that \texttt{Dep.Var} is
\href{https://lingmethodshub.github.io/content/R/lvc_r/110_lvcr.html}{re-coded
such that \texttt{Deletion} is the second factor}. Next, you
\href{https://lingmethodshub.github.io/content/R/lvc_r/112_lvcr.html}{set
the global \emph{R} options to employ sum contrast coding}.

\hypertarget{correlations-interactions-collinearity}{%
\subsection{Correlations, Interactions, \&
Collinearity}\label{correlations-interactions-collinearity}}

Lets look again at the results of the most parsimonious analysis of the
full data set.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(lme4)}
\NormalTok{td.glmer.parsimonious }\OtherTok{\textless{}{-}} \FunctionTok{glmer}\NormalTok{(Dep.Var }\SpecialCharTok{\textasciitilde{}}\NormalTok{ After.New }\SpecialCharTok{+}
\NormalTok{    Morph.Type }\SpecialCharTok{+}\NormalTok{ Before }\SpecialCharTok{+}\NormalTok{ Stress }\SpecialCharTok{+}\NormalTok{ Phoneme }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Speaker),}
    \AttributeTok{data =}\NormalTok{ td, }\AttributeTok{family =} \StringTok{"binomial"}\NormalTok{, }\AttributeTok{control =} \FunctionTok{glmerControl}\NormalTok{(}\AttributeTok{optCtrl =} \FunctionTok{list}\NormalTok{(}\AttributeTok{maxfun =} \DecValTok{20000}\NormalTok{),}
        \AttributeTok{optimizer =} \StringTok{"bobyqa"}\NormalTok{))}
\FunctionTok{summary}\NormalTok{(td.glmer.parsimonious)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [glmerMod]
 Family: binomial  ( logit )
Formula: Dep.Var ~ After.New + Morph.Type + Before + Stress + Phoneme +  
    (1 | Speaker)
   Data: td
Control: glmerControl(optCtrl = list(maxfun = 20000), optimizer = "bobyqa")

     AIC      BIC   logLik deviance df.resid 
    1114     1175     -545     1090     1177 

Scaled residuals: 
   Min     1Q Median     3Q    Max 
-5.223 -0.488 -0.259  0.495 14.033 

Random effects:
 Groups  Name        Variance Std.Dev.
 Speaker (Intercept) 0.796    0.892   
Number of obs: 1189, groups:  Speaker, 66

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)   -0.277      0.207   -1.34  0.18034    
After.New1     1.840      0.157   11.71  < 2e-16 ***
After.New2    -1.175      0.144   -8.14  4.1e-16 ***
Morph.Type1    0.426      0.140    3.05  0.00230 ** 
Morph.Type2   -1.892      0.213   -8.87  < 2e-16 ***
Before1       -0.575      0.202   -2.84  0.00447 ** 
Before2        0.526      0.193    2.72  0.00659 ** 
Before3        0.117      0.278    0.42  0.67370    
Before4        0.731      0.190    3.85  0.00012 ***
Stress1       -0.799      0.137   -5.81  6.2e-09 ***
Phoneme1       0.287      0.128    2.25  0.02462 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Correlation of Fixed Effects:
            (Intr) Aft.N1 Aft.N2 Mrp.T1 Mrp.T2 Befor1 Befor2 Befor3 Befor4
After.New1   0.064                                                        
After.New2  -0.104 -0.430                                                 
Morph.Type1 -0.434  0.203 -0.114                                          
Morph.Type2 -0.051 -0.221  0.178 -0.376                                   
Before1     -0.296 -0.223  0.293  0.052  0.429                            
Before2     -0.164  0.191 -0.094 -0.110  0.247  0.029                     
Before3      0.150  0.018 -0.060  0.319 -0.515 -0.421 -0.477              
Before4      0.250  0.304 -0.431 -0.202  0.051 -0.311 -0.090 -0.274       
Stress1     -0.434 -0.432 -0.064  0.050  0.097  0.056  0.125 -0.094 -0.250
Phoneme1     0.459  0.149 -0.307 -0.137 -0.265 -0.543 -0.263  0.149  0.438
            Strss1
After.New1        
After.New2        
Morph.Type1       
Morph.Type2       
Before1           
Before2           
Before3           
Before4           
Stress1           
Phoneme1    -0.107
\end{verbatim}

Below the results for fixed effects is a table of the correlations of
the fixed effects. This table is a good way to spot
non-\href{https://en.wikipedia.org/wiki/Orthogonality\#Statistics,_econometrics,_and_economics}{orthogonal}
effects you might not yet have caught (though you should have caught
these effects if you thoroughly explored your data using
\href{https://lingmethodshub.github.io/content/R/lvc_r/060_lvcr.html}{summary
statistics}). Look at only the coefficients for the correlations of
levels of \textbf{different} parameters. Generally any value over
\(|0.3|\)\footnote{Any absolute value greater than \(3\), or rather any
  positive value higher than \(+3\) or any negative value lower than
  \(-3\).} should be investigated further. If you have any correlations
over \(|0.7|\) you should be worried. In your table there is no
correlation higher than \(|0.7|\), but there are a few over \(|0.3|\):
\texttt{After.New1*Before4} \(|0.304|\); \texttt{After.New1*Stress1}
\(|0.432|\); \texttt{After.New2*Before4} \(|0.431|\);
\texttt{After.New2*Phoneme1} \(|0.307|\); \texttt{Morph.Type1*Before3}
\(|0.319|\); \texttt{Morph.Type2*Before3} \(|0.515|\);
\texttt{Before1*Phoneme1} \(|0.543|\); and \texttt{Before4*Phoneme1}
\(|0.438|\). These correlations suggest it might be worthwhile to
re-check the summary statistics, looking especially at the cross-tab of
\texttt{After.New} and \texttt{Before}, \texttt{After.New} and
\texttt{Phoneme}, \texttt{Morph.Type} and \texttt{Before},
\texttt{Morph.Type} and \texttt{Phoneme}, and \texttt{Before} and
\texttt{Phoneme}.\footnote{See also \emph{Notes on Interactions} by
  Derek Denis, available at
  \url{https://www.dropbox.com/s/7c4tzc8st5dmeit/Denis_2010_Notes_On_Interactions.pdf}.}

There are two other methods for testing for a relationship between your
fixed effect predictors that relate to the kind of relationship your
fixed effects predictors might have. The first is that the predictors
have an \textbf{interaction} the other is that they are (multi-)
\textbf{collinear}.

\hypertarget{interactions}{%
\subsubsection{Interactions}\label{interactions}}

An interaction arises when two independent fixed effects work together
to predict the variation of the application value. For example, based on
the
\href{https://lingmethodshub.github.io/content/R/lvc_r/080_lvcr.html}{Conditional
Inference Tree} analysis you know that it is not case that gender itself
explains the social variation in \texttt{Deletion} vs.~\texttt{Realized}
(this is confirmed by the
\href{https://lingmethodshub.github.io/content/R/lvc_r/112_lvcr.html}{analysis
of data from just young speakers}, where \texttt{Sex} is not
significant), nor is it that age explains the social variation
(confirmed by the non-significance of both \texttt{Age.Group} and
\texttt{Center.Age} in
\href{https://lingmethodshub.github.io/content/R/lvc_r/112_lvcr.html}{the
full model}). Instead, it seems that older men use \texttt{Deletion}
more frequently than everyone else. This is an interaction. It is the
combination of \texttt{Age.Group} and \texttt{Sex} that (potentially)
best explains the social variation. You can test this in your model by
creating an interaction group with these two fixed effect predictors.
You do this by including the interaction term \texttt{Sex*Age.Group} in
your analysis. To make things easier here you can simplify and again
consider middle-age and older speakers together. You can also drop
\texttt{Phoneme} as it is non-significant among both cohorts. When you
include an interaction term, the individual components of the
interaction will also be included as singular predictors.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create a simplified Age.Group.Simple column}
\NormalTok{td }\OtherTok{\textless{}{-}}\NormalTok{ td }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Age.Group.Simple =} \FunctionTok{cut}\NormalTok{(YOB, }\AttributeTok{breaks =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\ConstantTok{Inf}\NormalTok{,}
        \DecValTok{1979}\NormalTok{, }\ConstantTok{Inf}\NormalTok{), }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"Old/Middle"}\NormalTok{, }\StringTok{"Young"}\NormalTok{)))}

\CommentTok{\# Create a regression analysis with a}
\CommentTok{\# Sex*Age.Group.Simple interaction group}
\NormalTok{td.glmer.sex.age.interaction }\OtherTok{\textless{}{-}} \FunctionTok{glmer}\NormalTok{(Dep.Var }\SpecialCharTok{\textasciitilde{}}\NormalTok{ After.New }\SpecialCharTok{+}
\NormalTok{    Morph.Type }\SpecialCharTok{+}\NormalTok{ Before }\SpecialCharTok{+}\NormalTok{ Stress }\SpecialCharTok{+}\NormalTok{ Sex }\SpecialCharTok{*}\NormalTok{ Age.Group.Simple }\SpecialCharTok{+}
\NormalTok{    (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Speaker), }\AttributeTok{data =}\NormalTok{ td, }\AttributeTok{family =} \StringTok{"binomial"}\NormalTok{,}
    \FunctionTok{glmerControl}\NormalTok{(}\AttributeTok{optCtrl =} \FunctionTok{list}\NormalTok{(}\AttributeTok{maxfun =} \DecValTok{20000}\NormalTok{), }\AttributeTok{optimizer =} \StringTok{"bobyqa"}\NormalTok{))}

\FunctionTok{summary}\NormalTok{(td.glmer.sex.age.interaction)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [glmerMod]
 Family: binomial  ( logit )
Formula: 
Dep.Var ~ After.New + Morph.Type + Before + Stress + Sex * Age.Group.Simple +  
    (1 | Speaker)
   Data: td
Control: glmerControl(optCtrl = list(maxfun = 20000), optimizer = "bobyqa")

     AIC      BIC   logLik deviance df.resid 
    1117     1188     -545     1089     1175 

Scaled residuals: 
   Min     1Q Median     3Q    Max 
-4.305 -0.492 -0.266  0.492 14.222 

Random effects:
 Groups  Name        Variance Std.Dev.
 Speaker (Intercept) 0.695    0.834   
Number of obs: 1189, groups:  Speaker, 66

Fixed effects:
                       Estimate Std. Error z value Pr(>|z|)    
(Intercept)             -0.4344     0.1831   -2.37  0.01767 *  
After.New1               1.7895     0.1554   11.51  < 2e-16 ***
After.New2              -1.0791     0.1371   -7.87  3.6e-15 ***
Morph.Type1              0.4618     0.1385    3.34  0.00085 ***
Morph.Type2             -1.7712     0.2055   -8.62  < 2e-16 ***
Before1                 -0.3258     0.1695   -1.92  0.05454 .  
Before2                  0.6685     0.1870    3.58  0.00035 ***
Before3                  0.0159     0.2750    0.06  0.95386    
Before4                  0.5365     0.1696    3.16  0.00156 ** 
Stress1                 -0.7696     0.1368   -5.63  1.8e-08 ***
Sex1                    -0.2626     0.1359   -1.93  0.05322 .  
Age.Group.Simple1        0.1281     0.1371    0.93  0.35011    
Sex1:Age.Group.Simple1  -0.1750     0.1363   -1.28  0.19902    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\begin{verbatim}

Correlation matrix not shown by default, as p = 13 > 12.
Use print(x, correlation=TRUE)  or
    vcov(x)        if you need it
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{Anova}\NormalTok{(td.glmer.sex.age.interaction)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Analysis of Deviance Table (Type II Wald chisquare tests)

Response: Dep.Var
                      Chisq Df Pr(>Chisq)    
After.New            144.21  2    < 2e-16 ***
Morph.Type            74.39  2    < 2e-16 ***
Before                36.42  4    2.4e-07 ***
Stress                31.67  1    1.8e-08 ***
Sex                    3.71  1      0.054 .  
Age.Group.Simple       0.71  1      0.399    
Sex:Age.Group.Simple   1.65  1      0.199    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

What you can see from the \texttt{summary(td.glmer.sex.age.interaction)}
and \texttt{Anova(td.glmer.sex.age.interaction)} results is that this
interaction term is not significant and does not add explanatory value
to the analysis. The negative polarity of the estimate coefficient of
the interaction term \texttt{Sex1:Age.Group.Simple1} indicates that when
the level of \texttt{Sex} is \texttt{Female} (\texttt{1}) and
\texttt{Age.Group.Simple} is \texttt{Old/Middle} (\texttt{1}) the
overall probability decreases by \(-0.1750\). This coefficient
represents the extra effect of both predictors working together. The
\(p\)-value of \(0.19902\), however, indicates that this change is not
statistically different from zero/no effect. In other words, even though
we know older men use \texttt{Deletion} more frequently, the extra
effect of combining age and sex does not emerge as significant when the
influence of the linguistic predictors is considered. If you want to
home in on the older/middle men in your results, you can reorder the
\texttt{Sex} predictor. Using the \texttt{fct\_rev()} function, which
reverses the order of factors making the last ``missing'' factor first,
is the easiest way to do this.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create a regression analysis with a}
\CommentTok{\# Sex*Age.Group.Simple interaction group in which}
\CommentTok{\# \textasciigrave{}Male\textasciigrave{} equals Sex1}
\NormalTok{td.glmer.sex.age.interaction }\OtherTok{\textless{}{-}} \FunctionTok{glmer}\NormalTok{(Dep.Var }\SpecialCharTok{\textasciitilde{}}\NormalTok{ After.New }\SpecialCharTok{+}
\NormalTok{    Morph.Type }\SpecialCharTok{+}\NormalTok{ Before }\SpecialCharTok{+}\NormalTok{ Stress }\SpecialCharTok{+} \FunctionTok{fct\_rev}\NormalTok{(Sex) }\SpecialCharTok{*}\NormalTok{ Age.Group.Simple }\SpecialCharTok{+}
\NormalTok{    (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Speaker), }\AttributeTok{data =}\NormalTok{ td, }\AttributeTok{family =} \StringTok{"binomial"}\NormalTok{,}
    \FunctionTok{glmerControl}\NormalTok{(}\AttributeTok{optCtrl =} \FunctionTok{list}\NormalTok{(}\AttributeTok{maxfun =} \DecValTok{20000}\NormalTok{), }\AttributeTok{optimizer =} \StringTok{"bobyqa"}\NormalTok{))}

\FunctionTok{summary}\NormalTok{(td.glmer.sex.age.interaction)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [glmerMod]
 Family: binomial  ( logit )
Formula: Dep.Var ~ After.New + Morph.Type + Before + Stress + fct_rev(Sex) *  
    Age.Group.Simple + (1 | Speaker)
   Data: td
Control: glmerControl(optCtrl = list(maxfun = 20000), optimizer = "bobyqa")

     AIC      BIC   logLik deviance df.resid 
    1117     1188     -545     1089     1175 

Scaled residuals: 
   Min     1Q Median     3Q    Max 
-4.305 -0.492 -0.266  0.492 14.222 

Random effects:
 Groups  Name        Variance Std.Dev.
 Speaker (Intercept) 0.695    0.834   
Number of obs: 1189, groups:  Speaker, 66

Fixed effects:
                                Estimate Std. Error z value Pr(>|z|)    
(Intercept)                      -0.4344     0.1831   -2.37  0.01767 *  
After.New1                        1.7895     0.1554   11.51  < 2e-16 ***
After.New2                       -1.0791     0.1371   -7.87  3.6e-15 ***
Morph.Type1                       0.4618     0.1385    3.34  0.00085 ***
Morph.Type2                      -1.7712     0.2055   -8.62  < 2e-16 ***
Before1                          -0.3258     0.1695   -1.92  0.05454 .  
Before2                           0.6685     0.1870    3.58  0.00035 ***
Before3                           0.0159     0.2750    0.06  0.95385    
Before4                           0.5365     0.1696    3.16  0.00156 ** 
Stress1                          -0.7696     0.1368   -5.63  1.8e-08 ***
fct_rev(Sex)1                     0.2626     0.1359    1.93  0.05322 .  
Age.Group.Simple1                 0.1281     0.1371    0.93  0.35011    
fct_rev(Sex)1:Age.Group.Simple1   0.1750     0.1363    1.28  0.19902    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\begin{verbatim}

Correlation matrix not shown by default, as p = 13 > 12.
Use print(x, correlation=TRUE)  or
    vcov(x)        if you need it
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{Anova}\NormalTok{(td.glmer.sex.age.interaction)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Analysis of Deviance Table (Type II Wald chisquare tests)

Response: Dep.Var
                               Chisq Df Pr(>Chisq)    
After.New                     144.21  2    < 2e-16 ***
Morph.Type                     74.39  2    < 2e-16 ***
Before                         36.42  4    2.4e-07 ***
Stress                         31.67  1    1.8e-08 ***
fct_rev(Sex)                    3.71  1      0.054 .  
Age.Group.Simple                0.71  1      0.399    
fct_rev(Sex):Age.Group.Simple   1.65  1      0.199    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

You can see that the coefficient for the interaction term is identical,
but with reverse polarity. It indicates that when \texttt{Sex} is
\texttt{Male} and \texttt{Age.Group.Simple} is \texttt{Old/Middle} the
extra effect is \(+0.1750\), but again, as you saw above, this
difference is not significantly different from zero/no effect
\(p = 0.19902\).

An alternative way to test this interaction is to
\href{https://lingmethodshub.github.io/content/R/lvc_r/050_lvcr.html}{create
a four-way \texttt{Sex:Age.Group.Simple} interaction group} and include
it as a fixed effect. By doing this instead of testing for an extra
effect caused by the interaction of these two variables, you are instead
testing the difference in likelihood from the overall likelihood for
each combination of age and sex, and determining whether this is
significantly different from zero.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create a four{-}way interaction group}
\NormalTok{td }\OtherTok{\textless{}{-}}\NormalTok{ td }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{unite}\NormalTok{(}\StringTok{"Sex.Age.Group.Simple"}\NormalTok{, }\FunctionTok{c}\NormalTok{(Sex, Age.Group.Simple),}
        \AttributeTok{sep =} \StringTok{":"}\NormalTok{, }\AttributeTok{remove =} \ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{levels}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(td}\SpecialCharTok{$}\NormalTok{Sex.Age.Group.Simple))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "F:Old/Middle" "F:Young"      "M:Old/Middle" "M:Young"     
\end{verbatim}

The levels of the four-way interaction group are \texttt{F:Old/Middle},
\texttt{F:Young}, \texttt{M:Old/Middle}, and \texttt{M:Young}. If you
recreate your \texttt{glmer()} analysis, you should find that the third
level, \texttt{M:Old/Middle}, to have a positive coefficient
(\texttt{Deletion} more likely than the mean), and the others to have a
negative coefficient (\texttt{Deletion} less likely than the mean).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create a regression analysis with the}
\CommentTok{\# Age.Simple:Sex interaction group}
\NormalTok{td.glmer.sex.age.interaction }\OtherTok{\textless{}{-}} \FunctionTok{glmer}\NormalTok{(Dep.Var }\SpecialCharTok{\textasciitilde{}}\NormalTok{ After.New }\SpecialCharTok{+}
\NormalTok{    Morph.Type }\SpecialCharTok{+}\NormalTok{ Before }\SpecialCharTok{+}\NormalTok{ Stress }\SpecialCharTok{+}\NormalTok{ Sex.Age.Group.Simple }\SpecialCharTok{+}
\NormalTok{    (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Speaker), }\AttributeTok{data =}\NormalTok{ td, }\AttributeTok{family =} \StringTok{"binomial"}\NormalTok{,}
    \FunctionTok{glmerControl}\NormalTok{(}\AttributeTok{optCtrl =} \FunctionTok{list}\NormalTok{(}\AttributeTok{maxfun =} \DecValTok{20000}\NormalTok{), }\AttributeTok{optimizer =} \StringTok{"bobyqa"}\NormalTok{))}

\FunctionTok{summary}\NormalTok{(td.glmer.sex.age.interaction)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [glmerMod]
 Family: binomial  ( logit )
Formula: 
Dep.Var ~ After.New + Morph.Type + Before + Stress + Sex.Age.Group.Simple +  
    (1 | Speaker)
   Data: td
Control: glmerControl(optCtrl = list(maxfun = 20000), optimizer = "bobyqa")

     AIC      BIC   logLik deviance df.resid 
    1117     1188     -545     1089     1175 

Scaled residuals: 
   Min     1Q Median     3Q    Max 
-4.305 -0.492 -0.266  0.492 14.222 

Random effects:
 Groups  Name        Variance Std.Dev.
 Speaker (Intercept) 0.695    0.834   
Number of obs: 1189, groups:  Speaker, 66

Fixed effects:
                      Estimate Std. Error z value Pr(>|z|)    
(Intercept)            -0.4344     0.1831   -2.37  0.01767 *  
After.New1              1.7895     0.1554   11.51  < 2e-16 ***
After.New2             -1.0791     0.1371   -7.87  3.6e-15 ***
Morph.Type1             0.4618     0.1385    3.34  0.00085 ***
Morph.Type2            -1.7712     0.2055   -8.62  < 2e-16 ***
Before1                -0.3258     0.1695   -1.92  0.05454 .  
Before2                 0.6685     0.1870    3.58  0.00035 ***
Before3                 0.0159     0.2750    0.06  0.95386    
Before4                 0.5365     0.1696    3.16  0.00156 ** 
Stress1                -0.7696     0.1368   -5.63  1.8e-08 ***
Sex.Age.Group.Simple1  -0.3095     0.2161   -1.43  0.15206    
Sex.Age.Group.Simple2  -0.2158     0.2441   -0.88  0.37667    
Sex.Age.Group.Simple3   0.5658     0.2557    2.21  0.02692 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\begin{verbatim}

Correlation matrix not shown by default, as p = 13 > 12.
Use print(x, correlation=TRUE)  or
    vcov(x)        if you need it
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{Anova}\NormalTok{(td.glmer.sex.age.interaction)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Analysis of Deviance Table (Type II Wald chisquare tests)

Response: Dep.Var
                      Chisq Df Pr(>Chisq)    
After.New            144.21  2    < 2e-16 ***
Morph.Type            74.39  2    < 2e-16 ***
Before                36.42  4    2.4e-07 ***
Stress                31.67  1    1.8e-08 ***
Sex.Age.Group.Simple   5.62  3       0.13    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

By using this four-way interaction group you can see that the
\texttt{M:Older/Middle} (\texttt{Sex.Age.Group.Simple3}) coefficient is
negative, and it is significantly different from zero/no effect. To find
the coefficient for the missing fourth value, re-create the analysis
using \texttt{fct\_rev()}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create a regression analysis with the reversed}
\CommentTok{\# Age.Simple:Sex interaction group}
\NormalTok{td.glmer.sex.age.interaction }\OtherTok{\textless{}{-}} \FunctionTok{glmer}\NormalTok{(Dep.Var }\SpecialCharTok{\textasciitilde{}}\NormalTok{ After.New }\SpecialCharTok{+}
\NormalTok{    Morph.Type }\SpecialCharTok{+}\NormalTok{ Before }\SpecialCharTok{+}\NormalTok{ Stress }\SpecialCharTok{+} \FunctionTok{fct\_rev}\NormalTok{(Sex.Age.Group.Simple) }\SpecialCharTok{+}
\NormalTok{    (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Speaker), }\AttributeTok{data =}\NormalTok{ td, }\AttributeTok{family =} \StringTok{"binomial"}\NormalTok{,}
    \FunctionTok{glmerControl}\NormalTok{(}\AttributeTok{optCtrl =} \FunctionTok{list}\NormalTok{(}\AttributeTok{maxfun =} \DecValTok{20000}\NormalTok{), }\AttributeTok{optimizer =} \StringTok{"bobyqa"}\NormalTok{))}

\FunctionTok{summary}\NormalTok{(td.glmer.sex.age.interaction)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [glmerMod]
 Family: binomial  ( logit )
Formula: 
Dep.Var ~ After.New + Morph.Type + Before + Stress + fct_rev(Sex.Age.Group.Simple) +  
    (1 | Speaker)
   Data: td
Control: glmerControl(optCtrl = list(maxfun = 20000), optimizer = "bobyqa")

     AIC      BIC   logLik deviance df.resid 
    1117     1188     -545     1089     1175 

Scaled residuals: 
   Min     1Q Median     3Q    Max 
-4.305 -0.492 -0.266  0.492 14.222 

Random effects:
 Groups  Name        Variance Std.Dev.
 Speaker (Intercept) 0.695    0.834   
Number of obs: 1189, groups:  Speaker, 66

Fixed effects:
                               Estimate Std. Error z value Pr(>|z|)    
(Intercept)                     -0.4344     0.1831   -2.37  0.01767 *  
After.New1                       1.7895     0.1554   11.51  < 2e-16 ***
After.New2                      -1.0791     0.1371   -7.87  3.6e-15 ***
Morph.Type1                      0.4618     0.1385    3.34  0.00085 ***
Morph.Type2                     -1.7712     0.2055   -8.62  < 2e-16 ***
Before1                         -0.3258     0.1695   -1.92  0.05454 .  
Before2                          0.6685     0.1870    3.58  0.00035 ***
Before3                          0.0159     0.2750    0.06  0.95386    
Before4                          0.5365     0.1696    3.16  0.00156 ** 
Stress1                         -0.7696     0.1368   -5.63  1.8e-08 ***
fct_rev(Sex.Age.Group.Simple)1  -0.0405     0.2273   -0.18  0.85860    
fct_rev(Sex.Age.Group.Simple)2   0.5658     0.2557    2.21  0.02692 *  
fct_rev(Sex.Age.Group.Simple)3  -0.2158     0.2441   -0.88  0.37668    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\begin{verbatim}

Correlation matrix not shown by default, as p = 13 > 12.
Use print(x, correlation=TRUE)  or
    vcov(x)        if you need it
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{Anova}\NormalTok{(td.glmer.sex.age.interaction)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Analysis of Deviance Table (Type II Wald chisquare tests)

Response: Dep.Var
                               Chisq Df Pr(>Chisq)    
After.New                     144.21  2    < 2e-16 ***
Morph.Type                     74.39  2    < 2e-16 ***
Before                         36.42  4    2.4e-07 ***
Stress                         31.67  1    1.8e-08 ***
fct_rev(Sex.Age.Group.Simple)   5.62  3       0.13    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

As with the other levels, \texttt{Men:Young}
(\texttt{fct\_rev(Sex.Age.Group.Simple)1}) is not significant. What you
can conclude is that all women and young men are not significantly
different from the overall probability (and by extension each other),
but old/middle men are significantly different from the overall
probability. Creating this four-way interaction group and including it
as a fixed effect reveals this pattern in a way that including the
interaction term \texttt{Sex:Age.Simple} does not. That being said, the
results of the \texttt{Anova()} indicate that this predictor still does
not add explanatory value to the analysis.

\hypertarget{collinearity}{%
\subsubsection{Collinearity}\label{collinearity}}

When fixed effects predictors are not independent we say they are
(multi-)
\href{https://www.britannica.com/topic/collinearity-statistics}{collinear}.
Collinearity and interactions are similar, but separate, phenomena.

Collinearity is the phenomenon whereby two or more predictor variables
are highly correlated, such that the value/level of one can be predicted
from the value/level of the other with a non-trivial degree of accuracy.
Including both in an anlysis 1) violates the assumptions of the model;
and 2) can actually result in diminished liklihood estimates for both
predictors, masking real effects. As discussed
\href{https://lingmethodshub.github.io/content/R/lvc_r/080_lvcr.html}{before},
in this Cape Breton data, \texttt{Education}, \texttt{Job}, and
\texttt{Age.Group} are all collinear to various degrees. For example, if
\texttt{Job} is \texttt{Student}, then the level of \texttt{Education}
can be predicted (it will also be \texttt{Student}), and vice versa. For
both, \texttt{Age.Group} can be predicted too (\texttt{Young}). These
types of correlations are easy to see for social categories, but
somewhat more difficult to tease out for linguistic categories. The
first step is always a thorough
\href{https://lingmethodshub.github.io/content/R/lvc_r/060_lvcr.html}{cross
tabulation} of your independent variables. For a quick visual of cross
tabulations you can employ a
\href{https://cran.r-project.org/web/packages/ggmosaic/vignettes/ggmosaic.html}{mosaic
plot}. Here is the code for creating a quick mosaic plot using
\texttt{ggplot2}, which you likely already have installed if you've
followed along with previous chapters.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Install ggmosaic package}
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"ggmosaic"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggmosaic)}
\FunctionTok{library}\NormalTok{(ggplot2)}
\CommentTok{\# Create a quick mosaic plot of Phoneme and}
\CommentTok{\# Before}
\FunctionTok{ggplot}\NormalTok{(td) }\SpecialCharTok{+} \FunctionTok{geom\_mosaic}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\FunctionTok{product}\NormalTok{(Dep.Var, Before,}
\NormalTok{    Phoneme), }\AttributeTok{fill =}\NormalTok{ Dep.Var)) }\SpecialCharTok{+} \FunctionTok{theme\_mosaic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics[width=0.75\textwidth,height=\textheight]{114_lvcr_files/figure-pdf/unnamed-chunk-9-1.pdf}

}

\end{figure}

In a mosaic plot the size of the box for each combination of variables
corresponds to the relative number of tokens of that combination. The
first major observation from the mosaic plot is that there are no
preceding /s/ tokens where the underlying phoneme is /d/, and there are
remarkably few tokens in which /d/ is preceded by a non-nasal
stop.\footnote{I checked the data and there are only three such tokens:
  one token of \emph{bugged} and two of \emph{hugged}.} This indicates
that you shouldn't include both of these predictors in your model, or
complexify the model by creating a interaction group of \texttt{Phoneme}
and \texttt{Before}. This is because you can predict some of the values
of \texttt{Phoneme} and \texttt{Before}. For example, if a token is
underlyingly world-final /d/, the preceding segment will not be /s/.
Likewise, if the preceding segment is /s/, the underlying phoneme must
be /t/.

Lets look at another mosaic plot.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create a quick mosaic plot of Phoneme and}
\CommentTok{\# Before}
\FunctionTok{ggplot}\NormalTok{(td) }\SpecialCharTok{+} \FunctionTok{geom\_mosaic}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\FunctionTok{product}\NormalTok{(Dep.Var, Before,}
\NormalTok{    After.New), }\AttributeTok{fill =}\NormalTok{ Dep.Var)) }\SpecialCharTok{+} \FunctionTok{theme\_mosaic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics[width=0.75\textwidth,height=\textheight]{114_lvcr_files/figure-pdf/unnamed-chunk-10-1.pdf}

}

\end{figure}

This plot is a little bit hard to read. To make the \emph{x}-axis labels
a little easier to read, you can use the binary version of
\texttt{Dep.Var}. You'll remember that \texttt{1} is \texttt{Deletion}
and \texttt{0} is \texttt{Realized}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create a quick mosaic plot of Phoneme and}
\CommentTok{\# Before}
\FunctionTok{ggplot}\NormalTok{(td) }\SpecialCharTok{+} \FunctionTok{geom\_mosaic}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\FunctionTok{product}\NormalTok{(Dep.Var.Binary,}
\NormalTok{    Before, After.New), }\AttributeTok{fill =}\NormalTok{ Dep.Var.Binary)) }\SpecialCharTok{+} \FunctionTok{theme\_mosaic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics[width=0.75\textwidth,height=\textheight]{114_lvcr_files/figure-pdf/unnamed-chunk-11-1.pdf}

}

\end{figure}

This mosaic plot show that there are very few tokens with a preceding
\texttt{Stop} and a following \texttt{Pause}. Though no apparent
collinearity is present, this mosaic plot does reveal some interesting
potential interactions. The effect of preceding /s/, liquids, and nasals
appears to be specific to pre-consonental contexts, and perhaps also
pre-vowel contexts for nasals. This suggests further exploration of the
data is warranted --- perhaps by creating separate \texttt{glmer()}
models for each following context, by complexifying your full model by
creating a \texttt{Before} and \texttt{After.New} interaction group, or
by simplifying your full model by
\href{https://lingmethodshub.github.io/content/R/lvc_r/040_lvcr.html}{collapsing
these two categories} into simpler grouped categories, e.g.,
\texttt{Pre-Pause}, \texttt{Liquid-Consonant}, \texttt{Liquid-Vowel},
\texttt{Nasal-Consonant}, \texttt{Nasal-Vowel}, \texttt{S-Consonant},
\texttt{S-Vowel}, \texttt{Other-Consonant}, \texttt{Other-Vowel}, or
similar.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create a new model using insights from the}
\CommentTok{\# mosaic plots}
\NormalTok{td }\OtherTok{\textless{}{-}}\NormalTok{ td }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Before.After =} \FunctionTok{factor}\NormalTok{(}\FunctionTok{paste}\NormalTok{(td}\SpecialCharTok{$}\NormalTok{Before, td}\SpecialCharTok{$}\NormalTok{After.New,}
        \AttributeTok{sep =} \StringTok{"."}\NormalTok{))) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Before.After =} \FunctionTok{recode\_factor}\NormalTok{(Before.After,}
        \AttributeTok{Liquid.Pause =} \StringTok{"Pause"}\NormalTok{, }\AttributeTok{Nasal.Pause =} \StringTok{"Pause"}\NormalTok{,}
        \StringTok{\textasciigrave{}}\AttributeTok{Other Fricative.Pause}\StringTok{\textasciigrave{}} \OtherTok{=} \StringTok{"Pause"}\NormalTok{, }\AttributeTok{S.Pause =} \StringTok{"Pause"}\NormalTok{,}
        \AttributeTok{Stop.Pause =} \StringTok{"Pause"}\NormalTok{, }\StringTok{\textasciigrave{}}\AttributeTok{Other Fricative.Consonant}\StringTok{\textasciigrave{}} \OtherTok{=} \StringTok{"Other.Consonant"}\NormalTok{,}
        \AttributeTok{Stop.Consonant =} \StringTok{"Other.Consonant"}\NormalTok{, }\StringTok{\textasciigrave{}}\AttributeTok{Other Fricative.Vowel}\StringTok{\textasciigrave{}} \OtherTok{=} \StringTok{"Other.Vowel"}\NormalTok{,}
        \AttributeTok{Stop.Vowel =} \StringTok{"Other.Vowel"}\NormalTok{))}


\NormalTok{td.glmer.parsimonious.new }\OtherTok{\textless{}{-}} \FunctionTok{glmer}\NormalTok{(Dep.Var }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Before.After }\SpecialCharTok{+}
\NormalTok{    Morph.Type }\SpecialCharTok{+}\NormalTok{ Stress }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{|}\NormalTok{ Speaker), }\AttributeTok{data =}\NormalTok{ td,}
    \AttributeTok{family =} \StringTok{"binomial"}\NormalTok{, }\FunctionTok{glmerControl}\NormalTok{(}\AttributeTok{optCtrl =} \FunctionTok{list}\NormalTok{(}\AttributeTok{maxfun =} \DecValTok{20000}\NormalTok{),}
        \AttributeTok{optimizer =} \StringTok{"bobyqa"}\NormalTok{))}

\CommentTok{\# Compare fit of new parsimonious model with old}
\CommentTok{\# parsimonious model}
\FunctionTok{anova}\NormalTok{(td.glmer.parsimonious, td.glmer.parsimonious.new)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Data: td
Models:
td.glmer.parsimonious: Dep.Var ~ After.New + Morph.Type + Before + Stress + Phoneme + (1 | Speaker)
td.glmer.parsimonious.new: Dep.Var ~ Before.After + Morph.Type + Stress + (1 | Speaker)
                          npar  AIC  BIC logLik deviance Chisq Df Pr(>Chisq)
td.glmer.parsimonious       12 1114 1175   -545     1090                    
td.glmer.parsimonious.new   13 1087 1153   -531     1061  28.6  1    8.7e-08
                             
td.glmer.parsimonious        
td.glmer.parsimonious.new ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

The \texttt{anova()} function shows that
\texttt{td.glmer.parsimonious.new} is a better fit model. In other
words, it does a better job of predicting the variation in the data.

It is important, however, to point out that collinearity does not reduce
the predictive power or reliability of the \texttt{glmer()} model as a
whole --- it only affects calculations regarding individual predictors.
That is, a \texttt{glmer()} model with correlated predictors can
indicate how well the entire bundle of predictors predicts the outcome
variable, but it may not give valid results about any individual
predictor, or about which predictors are redundant with respect to
others. In other words, collinearity prevents you from discovering the
three lines of evidence.

So how can you test whether your predictors are collinear? There are two
measures beyond just looking at the correlation matrix (which can point
to either collinearity or interaction).

The first method to test collinearity is to find the \textbf{Condition
Number} (\(\kappa\) a.k.a. kappa). The function to calculate this comes
from a \href{https://rdrr.io/github/jasongraf1/JGmermod/}{package}
created by linguist Jason Grafmiller, which adapts the
\texttt{collin.fnc()} function from Baayen's
\href{https://cran.r-project.org/web/packages/languageR/index.html}{\texttt{languageR}}
package to work with \texttt{lme4} mixed models. To install this package
you need to first install the \texttt{devtools()} package, and then you
can download it. We will return to the original
\texttt{td.glmer.parsimonious} to do this test.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Install JGermod}
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"devtools"}\NormalTok{)}
\NormalTok{devtools}\SpecialCharTok{::}\FunctionTok{install\_github}\NormalTok{(}\StringTok{"jasongraf1/JGmermod"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(JGmermod)}
\CommentTok{\# Calculate Condition Number}
\FunctionTok{collin.fnc.mer}\NormalTok{(td.glmer.parsimonious)}\SpecialCharTok{$}\NormalTok{cnumber}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 5.2
\end{verbatim}

The Condition Number here is less than \(6\) indicating no collinearity
Baayen (2008, 182). According to Baayen (citing Belsley, Kuh, and Welsch
1980), when the condition number is between \(0\) and \(6\), there is no
collinearity to speak of. Medium collinearity is indicated by condition
numbers around \(15\), and condition numbers of \(30\) or more indicate
potentially harmful collinearity.

The second measure of collinearity is determining the \textbf{Variable
Inflation Factor} (VIF), which estimates how much the variance of a
regression coefficient is inflated due to (multi)collinearity. The
function \texttt{check\_collinearity()} from the \texttt{performance}
package is used to calculate the VIF.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"performance"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(performance)}
\FunctionTok{check\_collinearity}\NormalTok{(td.glmer.parsimonious)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# Check for Multicollinearity

Low Correlation

       Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI
  After.New 2.68 [2.45, 2.94]         1.64      0.37     [0.34, 0.41]
 Morph.Type 2.06 [1.90, 2.25]         1.44      0.49     [0.44, 0.53]
     Before 4.93 [4.46, 5.46]         2.22      0.20     [0.18, 0.22]
     Stress 1.68 [1.56, 1.83]         1.30      0.59     [0.55, 0.64]
    Phoneme 1.87 [1.73, 2.04]         1.37      0.53     [0.49, 0.58]
\end{verbatim}

According to the
\href{https://rdrr.io/cran/performance/man/check_collinearity.html}{\texttt{performance}
package documentation}, a \texttt{VIF} less than \(5\) indicates a low
correlation of that predictor with other predictors. A value between
\(5\) and \(10\) indicates a moderate correlation, while VIF values
larger than \(10\) are a sign for high, not tolerable correlation of
model predictors (James et al. 2013). The \texttt{Increased\ SE} column
in the output indicates how much larger the standard error is due to the
association with other predictors conditional on the remaining variables
in the model.

Based on the Condition Number (\(\kappa<6\)) and the VIF (\(<5\)) you
can report that any (multi-) collinearity in your model is within
acceptably low limits. You can add this to your manuscript table, as in
Table 1 (based on \texttt{td.glmer.parsimonious}), though you should
always contextualize what these measures indicate (i.e., low
collinearity) in the text too.

  \begin{table}[h]
\noindent
\begin{center}
\begin{threeparttable}
\caption{Mixed-effects logistic regression testing the fixed effect of \textsc{Following Context},  \textsc{Morpheme Type}, \textsc{Preceding Context}, \textsc{Stress} and \textsc{Phoneme} and a random intercept of \emph{Speaker} on the deletion of word-final \textipa{/t, d/} in Cape Breton English}

\begin{tabular}{lrrrcrc}
\toprule
\multicolumn{5}{l}{AIC = 1114, Marginal $R^2$ = .40, Conditional $R^2$ = .52}&\multicolumn{2}{c}{Observations}\\
\cmidrule(lr){6-7} 
Fixed Effects: & \multicolumn{1}{c}{Estimate} & \multicolumn{1}{c}{Std. Error}&\multicolumn{1}{c}{\textit{z}-value}&\multicolumn{1}{c}{\textit{p}-value} &\multicolumn{1}{c}{\textit{n}}&\multicolumn{1}{c}{\% Deletion} \\
\midrule
\textsc{Intercept} (Grand Mean) & -0.277 & 0.207 & -1.34 &&1,189 &32\\
\textsc{Following Context} &&&&&\\
\quad\textit{Consonant} & 1.840&0.157&11.71&$\ast$$\ast$$\ast$ & 372 & 54\\
\quad\textit{Vowel} & -0.665&0.161&-4.13&$\ast$$\ast$$\ast$ & 259 & 28\\
\quad\textit{Pause} & -1.175&0.144&-8.14&$\ast$$\ast$$\ast$ & 558 & 20\\
\textsc{Morpheme Type} &&&&&\\
\quad\textit{Semi-Weak Simple Past}&1.466&0.207&7.10&$\ast$$\ast$$\ast$&116&63\\
\quad\textit{Mono-morpheme} & 0.426&0.140&3.05&$\ast$$\ast$$\ast$ & 762 & 37\\
\quad\textit{Weak Simple Past} & -1.892&0.213&-8.87&$\ast$$\ast$$\ast$ & 311 & 10\\
\textsc{Stress} &&&&&\\
\quad\textit{Unstressed}&0.799&0.137&5.81  &$\ast$$\ast$$\ast$ & 142 & 47\\
\quad\textit{Stressed} & -1.598&0.275&-5.81&$\ast$$\ast$$\ast$ & 1,047 & 31\\
\textsc{Preceding Context} &&&&&\\
\quad\textit{\textipa{/s/}}&0.731&0.190&3.85&$\ast$$\ast$$\ast$ &332 & 53\\
\quad\textit{Nasal} & 0.526&0.193&2.72&$\ast$$\ast$ & 209 & 39\\
\quad\textit{Other Fricative} & 0.117&0.278&0.42&& 130 & 15\\
\quad\textit{Liquid} & -0.575  &0.202&-2.84&$\ast$$\ast$ & 269 & 42\\
\quad\textit{Stop} & -0.799&0.189&-4.22&$\ast$$\ast$$\ast$ & 249 & 27\\
\textsc{Phoneme} &&&&&\\
\quad\textit{\textipa{/d/}}&0.287&0.128&2.25&$\ast$&878 &34\\
\quad\textit{\textipa{/t/}} &  -0.287&0.128&-2.25&$\ast$ & 311 & 29\\
\midrule
\multicolumn{5}{l}{Random Effects:} & \textit{sd} & \textit{n}\\
\midrule
\textsc{Speaker} &&&&& 0.892&  66\\
\bottomrule
\end{tabular}
\begin{tablenotes}
\item \hfill$\ast\ast\ast$~$p<0.001$,  $\ast\ast$~$p<0.01$, $\ast$~$p<0.05$\\[-10pt]
\item  Sum contrast coding. Estimate coefficients reported in log-odds. 
\item Model significantly better than null model (AIC = 1,456, $\chi^2$ = 362, df = 10, $\ast\ast\ast$)
\item Correlation of Fixed Effects $\le|0.54|$, $\kappa = 5.2$, Variable Inflation Factor $\le4.93$ 
\end{tablenotes}
\end{threeparttable}
\end{center}
\end{table} 

Keep in mind that if there are interaction terms (e.g.,
\texttt{Sex*Age.Group}) in your model high VIF values are expected. This
is because you are explicitly expecting and testing a correlation
between two predictors. The (multi-) collinearity among two components
of the interaction term is also called ``inessential ill-conditioning'',
which leads to inflated VIF values.

Also keep in mind that (multi-) collinearity might arise when a third,
unobserved variable has a causal effect on two or more predictors'
effect on the dependant variable. For example, correlated Education and
Job Type effects may be caused by an underlying age effect, if older
speakers are generally less educated and blue-collar workers and young
speakers are generally more educated and white collar workers. In such
cases, the actual relationship that matters is the association between
the unobserved variable and the dependant variable. If confronted with a
case like this, you should revisit what independent predictors are
included in the model. Non-inferential tools that can include (multi-)
collinear descriptors (like
\href{https://lingmethodshub.github.io/content/R/lvc_r/080_lvcr.html}{Conditional
Inference Trees} or
\href{https://lingmethodshub.github.io/content/R/lvc_r/090_lvcr.html}{Random
Forests}) may help you.

\hypertarget{references}{%
\subsubsection{References}\label{references}}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-Baayen2008}{}}%
Baayen, R. Harald. 2008. \emph{Analyzing Linguistic Data: A Practical
Introduction to Statistics Using {R}}. Cambridge: Cambridge University
Press.

\leavevmode\vadjust pre{\hypertarget{ref-Belsley1980}{}}%
Belsley, David A., Edwin Kuh, and Roy E. Welsch. 1980. \emph{Regression
Diagnostics: Identifying Influential Data and Sources of Collinearity}.
New York: Wiley.

\leavevmode\vadjust pre{\hypertarget{ref-James2013}{}}%
James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani.
2013. \emph{An Introduction to Statistical Learning: With Applications
in \emph{r}}. New York: Springer.
\url{https://link.springer.com/book/10.1007/978-1-4614-7138-7c}.

\end{CSLReferences}



\end{document}
