---
title: "Doing LVC with R (updated and revised)"
author: "Matt Hunt Gardner, PhD "
date: "`r Sys.Date()`"
licence: "CC-BY 4.0"
format: hugo
output-file: "_index.md"
draft: false
weight: 50
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(tidy='styler', tidy.opts=list(strict=TRUE, scope="tokens"), tidy = TRUE)
```

# Getting Started

## Introduction

These instructions are not intended to be a comprehensive overview of *R*'s functionality, which is myriad. Instead it is a set of very specific instructions for doing the kinds of things in *R* that variationist sociolinguists familiar with *Goldvarb* often want to do. This includes extracting summary statistics from a standard token spreadsheet and formatting those statistics in such a way that they can be graphed using the package **ggplot2**, as well as testing the trends in those summary statistics using mixed-effects logistic regression analysis. These instructions assume you have installed the latest version of *R* (4.1.3 or later ). Even though this guide does not show everything that *R* can do, after reading and working your way through this guide, you should be familiar enough with how *R* generally works to figure out how do something not covered.

::: {#sidebar style="color: #009fe3; background: #d8f0fa;"} <strong>Note:</strong> The best way to learn how to use *R* is to play with it. Learn by doing. You can't break *R*. It doesn't bite. Even though *R* is a cutting edge statistical tool, I compare the experience working with it to fixing an old car. Sometimes you just need to keep tinkering until the engine starts and runs smoothly. Other times you just need to kick it. :::

If you run into a problem you don't know how to solve, Google it. I guarantee someone has had the same question already. There are many, many online *R* tutorials. That's how I learned how to use *R*. That said, it still sometimes takes me many failed attempts before I get something right.

<center>![(#fig:tweet) Actual tweet](images/tweet.png)</center>

### *R* and *Goldvarb*

In this guide I mention the program [*Goldvarb*](http://individual.utoronto.ca/tagliamonte/goldvarb.html) a lot. This is a well-known and widely-used program for doing multivariate analysis in the language variation and change literature. If you are are unfamiliar with *Goldvarb* you can learn more in Sali Tagliamonte's (2006) [*Analysing Sociolingusitic Variation*](https://doi.org/10.1017/CBO9780511801624). I remain agnostic as to whether *R* or *Goldvarb* or any other analysis tool is the one you must use for your research. Each tool has pros and cons. These instructions are simply a set of procedures you can use if you choose to use *R*.

### Token Files

You should have one master Microsoft *Excel* spreadsheet for your data. From this master spreadsheet you can create other files that can be used in programs like *Goldvarb* and *R*. Each row of your spreadsheet should represent an individual token. Each column of your spreadsheet should represent a different, independent variable. The example token file for this guide is structured this way, as in Figure \@ref(fig:excel)

<center>![(#fig:excel) Example token file deletiondata.txt](images/tokenfile.png)</center>

::: {style="color: #009fe3; background: #d8f0fa;"} <strong>Note:</strong> Do not include anything in your token file that isn't a token. Do not create sum columns. Do not add random notes to the right or the top of the data. *R* will try to interpret all of this as data. :::

### R Script Files

Anytime you are using *R* you should be using script files. Script files are very similar to *Goldvarb* condition files. They are files that include instructions that tell *R* what to do. By saving your command functions in script files you create replicability for your work in *R*. You may have *pseudo*-script files already. Many people keep a text file full of useful *R* command functions. An *R* script file is an *R*-specific file that does the same thing.

I cannot stress enough the importance of replicability. You always want to be able to go back and see every step you took in your analysis. This is especially true in the frequent situation where a reviewer suggests you go back and double-check something in your data or tweak your analysis in some way. Using script files, which are essentially a log of all your steps, is an excellent way to ensure replicability.

<center>

\caption{Example *R* script file}

![(#fig:scriptfile) Example *R* script file](images/scriptfile.png)

</center>

Some people have one script file for an entire project --- say, a paper. My co-author Derek Denis does this. Other people have specific script files for specific results --- e.g., one script file for each graph with the complete instructions for making that one graph, and the script file and the graph it creates labelled identically. This is the method I prefer. You may choose to do either, or both, or choose not to use script files at all. It's up to you.

All of the functions discussed in this workshop are in a single *R* script file whichis replicated at the end of this guide.

If you download this file and open it, *R* will automatically open for you. If you want to create a new *R* script file after you've opened *R* you can do so via the **File** menu: **File\>New Document**.

\##*R* and *R Studio*

The following instructions assume you are using the core *R* program, not *R Studio*. There is no real difference between these programs (at least in how *R* operates). *R Studio* is just an alternative user interface. Some of the external commands (e.g. creating a new *R* script file, etc.) may be different, but the actual *R* functions listed in this document will be the same. There is no advantage to using the *R* core program or *R Studio*. The choice is simply personal preference. I prefer the core *R* program because I like to be able to see multiple script files at the same time. *R Studio* organizes script files in tabs.

To execute a command function that is in a script file simply put your cursor on the same line as that command and press the execution or **Run** command depending on your operating system and editor. In Figure \@ref(fig:scriptfile) the cursor is placed in the middle of line 2; pressing `Control+Return` on my Mac executes the command function highlighted in grey. You can also highlight a large portion, or even all of your script file, and press the execution command to execute multiple commands at once. There is also an execute all or **Source** command that will execute the entire script file.

| Execute    | Mac OSX          | Windows PC   |
|------------|------------------|--------------|
| *R* Editor | `Command+Return` | `CTRL+R`     |
| *R Studio* | `Command+Return` | `CTRL+Enter` |

------------------------------------------------------------------------

| Execute    | Mac OSX            | Windows PC     |
|------------|--------------------|----------------|
| *R* Editor | `Command+E`        | `CTRL+Shift+R` |
| *R Studio* | `Command+Option+R` | `CTRL+Alt+R`   |

### Installing Packages

Before you begin doing any kind of analysis in *R*, you'll first need several \`packages.' Packages are simply additional sets of instructions that can do things above and beyond *R*'s core functionality. Packages are created by academics and are made available to everyone. *R* doesn't automatically download every package, so if you want to use a specific package, you must download it. You only need to do this one time. You also need to be connected to the internet to do it. Type the following function into *R*'s console window and press **Enter/Return** or type it into a script file and press **CTRL+Enter/Command+Return**:

```{r eval=FALSE}
install.packages(c("dplyr","vcd","reshape2","ggplot2","partykit","lme4","car","multcomp", "MuMIn"), dependencies = TRUE)
```

Above `install.packages()` is a function for installing packages. Inside the parentheses you tell *R* which packages to install. In this case you want to install multiple packages. Any time you need to combine multiple things in *R* you use the concatenating function `c()`. So the above function says combine the package names `dplyr`,`vcd`, `reshape2`, `ggplot2`, `partykit`, `lme4`, `car`, `multcomp`, and`MuNIn` and then install the packages with those names. The `dependencies = TRUE` specification tells *R* to install any additional packages that these packages depend on to function.

When you execute this function, *R* might ask you to pick a **CRAN Mirror**. This is just *R* asking you from where you want to download the packages. *CRAN* is the *Comprehensive R Archive Network* and mirrors are simply different institutions that offer identical copies of *R* files for downloading. Usually I just pick the option closest to me, which is the University of Toronto in Canada. If you've downloaded packages in the past you've likely already set your **CRAN Mirror**, and won't be prompted to do it again.

Once you've selected your **CRAN Mirror**, if necessary, and executed the **install.packages()** function, you may see a bunch of text scroll across your *R* console window. This is just *R* telling you that it is downloading and installing these packages. You can also install packages by selecting **Packages & Data \> Package Installer**. In this window click **Get List**, then search/browse for the required packages one by one. When you find a package, highlight it and click **Install Selected**. Make sure the **Install Dependencies** option is checked.

As *R* updates over time, so too must these packages. But packages don't update automatically. Therefore it's a good idea to periodically execute the function below. Do this now. These instructions assume that you have the most up to date version of *R* and its packages. The `ask=FALSE` option for the `update.packages()` function just means that *R* will run the update 'silently", or rather, it won't ask you whether or not you want to update each individual package you've installed.

```{r eval=FALSE}
update.packages(ask=FALSE)
```

## Getting your data into *R*

The best way to organize your tokens is in a spreadsheet in Microsoft *Excel*. There are a lot of useful tools in Microsoft *Excel* for automatically coding and re-coding your data. Some of those tools overlap with what I present here for *R*. If you want to explore *Excel*'s functionality, I recommend this website as a springboard: <https://support.office.com/en-us/article/Excel-training-9bc05390-e94c-46af-a5b3-d7c22f6990bb>. There are other programs for spreadsheet management: *Numbers* in OSX, or Google's *Sheets*, for example. They generally function similarly to *Excel*. *R* does not easily read *Excel*'s default file type (**.xls** or **.xlsx**, [though it can be done](https://cran.r-project.org/web/packages/xlsx/xlsx.pdf)) therefore, you must save your token file as a tab-delimited-text file (**.txt**) or a comma-separated-values (**.csv**) file.

::: {style="color: #009fe3; background: #d8f0fa;"} <strong>Note:</strong> I recommend NOT saving your token files as a .**csv file**. Often your token files will include a column of cells containing the broader context the token was extracted from. For example, the sentence in which it appears in a transcript. This broader context usually includes commas. If this is the case, when you save your file as a **.csv file**, it will appear as if there are column breaks in the middle of your broader context because commas are used as the column delimiter. :::

There are four or five ways to read data into *R*. Which method you choose is really up to you, but because I'm advocating the use of *R* script files and maximum replicability, I suggest using the following function at the top of your script file:

```{r eval=TRUE}
td <- read.delim("Data/deletiondata.txt")
```

The function creates an *R* "object" called `td` and then uses the assignment operator `<-` to specify what that object is. In this case `td` is the contents of the tab-delimited text file called `deletiondata.txt` that is located in a folder called `Doing\_LVC\_with\_R`, in a folder called `R` in a folder called `Dropbox` on the root drive of my computer. This tab-delimited text file is my data file. You can download this same file [here](https://www.dropbox.com/s/hynh5uqxqi8azlb/deletiondata.txt%7D%7Bhttps://www.dropbox.com/s/hynh5uqxqi8azlb/deletiondata.txt). Wherever you save this file, write that file path in quotation marks inside the `read.delim()` function. On a PC this file path will likely begin `"C:/..."`. You can actually just read the file directly into *R* from the web link using the following function:

```{r eval=FALSE}
td <-read.delim("https://www.dropbox.com/s/jxlfuogea3lx2pu/deletiondata.txt?dl=1")
```

This data file is a token file for a project studying the rates of word-final (t, d) deletion collected for Gardner (2010; 2017) among English speakers on Cape Breton Island, Nova Scotia, Canada.

If you prefer to save your data files as comma-separated-values files (even though you shouldn't, see above), you can read them into *R* using the function `read.csv2()`. If you find it tricky to figure out the file path of your data file you can instead write `file.choose()` (OS X) or `choose.files()` (PC) instead of the file path inside the `read.delim()`/`read.csv2()` function, with no quotation marks. This will create a pop-up window where you can browse through your files and select one. While this *seems* easier, it is not worth it. By not explicitly writing out the file path you introduce a non-replicable element in your script file because there is no record of what you browse to in the actual script file. This means that if you return to your project a year later, or someone else is looking over your code, it might not be clear which data file is supposed to be used. If you choose to use an *R* script file you can actually just drag and drop your data file (or any file) into the script window itself and the full file path will be automatically inserted.

You can also copy a file's filepath to the clipboard on a Mac by pressing **Control** while clicking on the file, then pressing **Option** and selecting **Copy "\[your file\]" as Pathname**. On a PC you can do the same thing by right-clicking on a file, or (if using Windows 10) using the **Copy path** button on the **Home** tab ribbon in *Windows File Explorer*.

For more information about reading files into *R*, go [here](https://stat.ethz.ch/R-manual/R-devel/library/utils/html/read.table.html)

##Getting to know the data

### Getting a Snapshot of the Data

Now that you have some data loaded into *R* you can start exploring it. At any time you can type `td` into the console window to see what that object actually represents. Try it.

```{r,attr.output='style="max-height: 100px;"', R.options = list(width = 1000)}
td
```

To find out how many columns there are in your data frame (this is what *R* calls spreadsheets), use the function `nrow()`. Similarly, to find out how many columns are in the data frame, use the function `ncol()`. The function `dim()` gives both.

```{r}
nrow(td)
ncol(td)
dim(td)
```

There are 6,989 rows and 12 columns in this data frame.

The `summary()` function is one of the most useful functions you'll use in R. It gives you a quick snapshot of a data frame.

```{r}
summary(td)
```

The `summary()` function shows you the name of all the columns in the data frame and what each column contains.

When you import a data frame into *R*, *R* automatically decides what type of data each column contains. Any data frame columns where all cells contain only numbers are assumed to `numeric` or `integer` data (depending on if there are decimal values). Any columns that include letters will be assumed to be `character` data.

For `numeric` or `integer` data, the `summary()` function it will tell you the mean, the median, the minimum value, the maximum value, and the values of the first and third quartiles. The mean is the arithmetic mean, which is the sum of all the values in a column divided by the number of values in a column. Fifty percent of the values in the column are equal to or less than the mean and 50% of the values in the column are greater than or less than the mean. The mean can also be thought of as the 2nd quartile. The median is the most frequent value in the column. For *normally distributed* data, the mean and the median should be close to the same value. Not all data, however, is normally distributed, which is sometimes a problem, and sometimes not a problem. If a certain test expects numerical data to be normally distributed these instructions will explain what to do, but for now, it's just good to know what mean and median indicate. Twenty-five percent of the values in the column are equal to or less than the 1st quartile and 75% of the values in the column are equal to or less. The minimum value is the lowest value in a column; the maximum value is the highest number in a column. These values can be used to construct a **box and whisker** plot:

```{r echo=F, message=FALSE, warning=FALSE, fig.cap="Box and whisker plot of `YOB` (Year of Birth) in the `td` data frame"}
library(ggpubr)
library(ggplot2)
library(plotly)
p<-ggplot(td, aes(y=YOB))+
  geom_boxplot(fill="lightblue1", color="dodgerblue")+
   theme_pubclean()+
  theme(axis.ticks.x=element_blank(),  axis.text.x=element_blank())
ggplotly(p)
```

The bottom **whisker** displays the minimum value of 1910. The bottom line of the **box** displays the first quartile value of 1952. The black bar in the middle of the **box** displays the second quartile value/mean of 1965. The top line of the *box* displays the third quartile value of 1991. The range from the first quartile to the third quartile is called the **interquartile range**. The top **whisker** displays the maximum value of 1999.

The function `names()` returns a vector (a series of items in a line, separated by commas) of the column names. This function can be useful as a quick way to get the names of each column. You will need to use these names quite often when writing other commands. `colnames()` returns the same information; `ls()` returns the same information, but ordered alphabetically.

```{r}
names(td)
colnames(td)
ls(td)
```

The function `str()` describes the structure of a data frame. It reports similar information as `summary()` but does not include descriptions of each column; however, the layout of the information is sometimes a little easier to read, especially if your data frame has many columns. Here we can see that `YOB` is categorized as `int` (integer) data and all the other columns are `chr` (character) data.

```{r}
str(td)
```

`head()` will return the first six lines of the data frame. `tail()` provides the last six. For either you can change the number of lines reported using the option `n=`.

```{r,attr.output='style="max-height: 100px;"', R.options = list(width = 1000)}
head(td)
```

The numbers on the left side of the output are the row number in the data frame.

```{r,attr.output='style="max-height: 100px;"', R.options = list(width = 1000)}
tail(td, n=10)
```

### Types of Data

There are other types of data beside `numerical` (like `YOB` in the `td` data) and `character` (like all other columns in the `td` data).

| Data Type   | Description                                                           | Example                                                                               |
|--------------|--------------------------|--------------------------------|
| `logical`   | either `TRUE` or `FALSE`                                              | The answer to a question like "is `x` a number?", etc.                                |
| `numeric`   | any real number, positive or negative, with or without decimal values | Vowel formant measurements, position in an audio file, household income, etc.         |
| `integer`   | whole numbers and their negative counterparts                         | year of birth, year of data collection, number of occurrences of something, etc.      |
| `complex`   | data that includes imaginary or unknown elements                      | the pythagorian theroem, i.e., `a^2 + b^2 = c^2`, where `a`, `b`, and `c` are unknown |
| `character` | single characters (like `'F'`) or **strings** (like `"female"`)       | gender, speaker name, etc.                                                            |
| `raw`       | raw bytes                                                             | Anything expressed in bytes                                                           |

::: {style="color: #009fe3; background: #d8f0fa;"} <strong> Note: </strong> Character data is always enclosed in either single quotes `' '` or double quotes `" "`. It is common practice to use single quotes for single characters and double quotes fro stringer, though either will work with either. :::

It is uncommon to use `raw` data in sociolinguistics. Anything can be expressed in bytes. There are two functions to convert from characters to bytes, and bytes to characters. To go from characters to bytes:

```{r, echo = T}
raw_variable <- charToRaw("Sociolinguistics is fun")
print(raw_variable)
print(class(raw_variable))
```

Above the function `charToRaw()` converts the string `"Sociolinguistics is fun"` to bytes and assigns that raw data to the object `raw_variable`. Next the `print()` function displays in *R* the contents of the variable `raw_variable`. The `class()` function returns the type of data contained within a variable. To convert back to characters:

```{r, echo = T}
 char_variable <- rawToChar(raw_variable)
print(char_variable)
print(class(char_variable))
```

### Types of Data Structures

A **vectors** and **lists** are the most basic types of data structures. A **vector** is a collection of elements, most commonly a collection of `character`, `logical`, `integer`, or `numeric` values. Values can be combined into a vector using the concatenating function `c()`

```{r}
simple.vector <- c("Labov", "Fishman")
print(simple.vector)
```

We can explore the vector using some of the same functions we've already seen.

```{r}
length(simple.vector)
class(simple.vector)
str(simple.vector)
```

**Lists** are like **vectors** but can contain a mixture of different data types. Characters must be in quotation marks. Numbers in quotation marks will be categorized as characters. Numeric data is numbers without quotation marks. Integers are specificed by adding `L` after the number. Logical values are either `TRUE` or `FALSE` in all capital letters.

```{r,attr.output='style="max-height: 100px;"', R.options = list(width = 1000)}
simple.list<-list("Labov", "Fishman","2001", 1963, 1.5, 1974L, TRUE)
print(simple.list)
length(simple.list)
class(simple.list)
str(simple.list)
```

You will notice that the results of the `str()` function show that `Labov`, `Fishman` and `2001` are all categorized as `chr` (character); `1963` and `1.5` are categorized as `num` (numeric); `1974` is categorized as `int` (integer); and `TRUE` is categorized as `logi` (logical).

Lists can be bigger than just one group of data. Items in a list can also be more complex than a single value.

```{r,attr.output='style="max-height: 100px;"', R.options = list(width = 1000)}
complex.list <- list(a = "John Baugh", b = simple.vector, c=simple.list, d=head(td))
print(complex.list)
str(complex.list)
```

In the list `complex.list` column `a` contains only one value: `John Baugh`. Column `b` contains our `simple.vector`, column `c` contains our `simple.list`, and column `d` includes the first six rows of the `td` data (which itself has columns). To access the values from columns within columns you can use multiple `$` operators.

```{r,attr.output='style="max-height: 100px;"', R.options = list(width = 1000)}
print(complex.list$a)
print(complex.list$d)
print(complex.list$d$Job)
```

Generally, in LVC analysis we do not deal often with either simple vectors or lists; instead, most of our data is in a spreadsheet-like format, which in *R* is a **data frame**.

**Data frames** are a special type of **list** in which every element in the **list** has the same length (unlike, for example, the `complex.list` above). **Data frames** can have additional annotations, like `rownames()`. Some statisticians use `rownames()` for things like `participantID`, `sampleID`, or some other unique identifier. Most of the time (and for our purposes), `rownames()` are not useful given that we have multiple rows from the same speaker/interview, etc.

### Factors and Comments

A *factor* in *R* is a special type of variable or data type that, in theory, has a limited number of values. Each value is called a *level*. Any **vector** or **data frame** column of `character` or `integer` values can be a **factor**. Most non-numerical data in LVC is generally thought of as a **factor** already, so knowing how to convert **vectors** or **data frame** columns to factors is important. For example, in the `td` data, the column `Stress` contains only two options: `Stressed` and `Unstressed`. Because this column contains letters, when we imported it into *R*, it was automatically categorized as `character` data. This is probably the best option for a column that, for example, contained the broader context of a token. For `Stressed`, however, it is better for our purposes for *R* to consider the column as containing a **factor** with two discrete levels. Below is the code to convert `Stress` into a **factor**.

```{r}
# Determine the class of the column Stress in the date frame td
class(td$Stress)
```

```{r}
# Convert Stress to a column to a factor
td$Stress <-factor(td$Stress)
class(td$Stress)
```

Notice the **comments** in the code above. In *R* any line that begins with a `#` is not evaluated. This is called *commenting out* a line. We use `#` to include notes in our codes, or to keep code in our script file but have *R* ignore it. This can be useful in order to keep track of the steps you are taking in an analysis (see also [this tutorial](https://support.rstudio.com/hc/en-us/articles/200484568-Code-Folding-and-Sections-in-the-RStudio-IDE) on organizing code using `#`)

Columns within a data frame can be specified using the `$` operator So, above, we tell *R* to assign (using the assignment operator `<-`) the values of the original `td$Stress` column, converted into **factors**, back to the column `td$Stress`. In other words, we are replacing the original column `td$Stress` with a converted version of itself. Now, look how the output of the `summary()` function changes.

```{r}
summary(td)
```

We get the number of observations of each level of `td$Stress` instead of just the number of rows (i.e. the `length` of the column).

To get the levels of a **factor** we can use the function `levels()` and to get the number of levels, we can use the function `nlevels(`)\`

```{r}
levels(td$Stress)
nlevels(td$Stress)
```

## More Exploring

If you only want information from a single column of the data frame, you can use the operator `$` to specify which column of `td` you want. Here the column \`Sex' is specified.

```{r}
summary(td$Sex)
levels(td$Sex)
```

The `Sex` column is still categorized as `character` data and so `summary()` only return the number of rows (`length`) of the column and there are no levels. To get the information we want about the `Sex` column (i.e., how many tokens are from male speakers and how many are from women speakers) we need to convert it to a factor first. We can either convert the the column to a factor column, or we can use the `as.factor()` function to have *R* treat is as a factor in just the following code.

```{r}
summary(as.factor(td$Sex))
levels (as.factor(td$Sex))
```

The following code changes all the character class columns to factors.

```{r}
# We start with a fresh import of the (t, d) data into R
td <- read.delim("Data/deletiondata.txt")
# Now we convert each character column into a factor
td$Dep.Var <- factor(td$Dep.Var)
td$Stress <- factor(td$Stress)
td$Category <- factor(td$Category)
td$Morph.Type<- factor(td$Morph.Type)
td$Before <- factor(td$Before)
td$After <- factor(td$After)
td$Speaker <- factor(td$Speaker)
td$Sex <- factor(td$Sex)
td$Education <- factor(td$Education)
td$Job <- factor(td$Job)
td$Phoneme.Dep.Var <- factor(td$Phoneme.Dep.Var)
```

## The (t/d) Data

Let's look at the data now that all the character columns are factors.

```{r}
summary(td)
```

As shown in the `summary(td)` results above, the first column in the (t, d) deletion data is called `Dep.Var` and it includes two levels: `Realized` and `Deletion`. These two levels represent the two options for each token of (t, d). The values after each level are how many rows are coded with that level. In other words, there are 1,747 rows (or tokens) of `Deletion` and there are 5,242 rows (or tokens) of `Realized`. Notice that the order of the factor levels is alphabetical. There is a column labelled `Stress` which indicates if the (t, d) token is in a stressed or unstressed syllable. The `Category` column indicates if the word in which the (t, d) token appears is a function or lexical word. `Morph.Type` indicates if the (t, d) occurs in a monomorpheme (like *fist*), a semi-weak simple past-tense verb (like *dealt* ) in which there is a vowel change and a (t,d) sound is added, or a weak simple past-tense verb (like *walked*) in which just /*-ed*/ is added. `Before` indicates the type of sound preceding the (t, d) and `After` indicates the sound following the (t, d). `Speaker` is a unique identifier for each participant in the data (only the first six are displayed, though); `YOB` indicates the speaker's year of birth, `Sex` his or her sex[^1], `Education` his or her education level, and `Job` his or her job type. Finally, `Phoneme.Dep.Var` indicates the canonical underlying phoneme of the (t, d) token and a more detailed coding of the dependent variable.

[^1]: These were the only two sex/gender identities reported by speakers in this data.

# Modifying Data

Deleting tokens, recoding tokens, combining factor groups, etc. is, in my opinion, easier to do in *Excel*. But, if you want to do this in *R*, or you only want to perform the modification for a specific analysis or graph, you may find the following functions useful.

## Removing Rows

This (t, d) deletion data includes tokens in which the previous phoneme is a vowel. Many analyses of (t, d) deletion exclude this context. Here is how to remove these contexts from your data frame.

```{r}
td <-td[td$Before != "Vowel",]
summary(td)
```

The first line of code creates a new object called `td`. The `<-` operator means you're telling *R* that this new `td` is the same as the old `td`, but filtered according to some specific condition. You could also use the `<-` operator to create a new `td` with a different name --- e.g., `td.new <- td[td\$Before != "Vowel",]}` --- thus giving you two data frames (`td` and `td.new`) to work with.

Throughout *R*, square brackets `[ ]` are used for specifying filtering conditions. The first line of code therefore says make new `td` the same as old `td`, but only where the value in the `Before` column of old `td` (indicated by `td$Before`) does not equal `"Vowel"`. `!=` is the standard operator meaning *does not equal*. The comma after `"Vowel"` is important. If you are filtering a data frame, as you are here, *R* needs to know where to look for the values you want to keep or throw out. It follows this format: `data frame[rows,columns]`. So the comma in the above function line indicates that the filtering condition relates to values found while searching row by row. It selects any row in which the value in the `Before` column does not equal `"Vowel"`. The quotation marks around `"Vowel"` are also important because the values in the `Before` column are all strings of characters, which (you'll remember from above), are always enclosed in quotation marks.

```{r}
td$Before <-factor(td$Before)
```

An additional line of code is needed for resetting the data structure. The new `td` inherits the data structure from the old `td`. This means *R* thinks the new `td` still has a level in the column `Before` called `"Vowel"` --- even though there are zero tokens now in the column with this value. If you run `summary(td)` after the first code above you'll see that *R* still lists `"Vowel"` as a possible level of `Before`, but with zero instances. The additional line of code tells *R* to make a new column `Before` in the data frame `td` (this will replace the old `Before` column) in which the possible factors (i.e., values) in that column are those that actually exist in the new `Before` column in `td`. Run `summary()` or `str()` now and you'll see that the empty `"Vowel"` level is gone.

```{r}
summary(td)
str(td)
```

The following code does exactly the same thing as the previous code, but instead of filtering out `"Vowel"`, it specifies keeping all the other levels. Here `==` is the standard operator meaning *equals and only equals* and `|` (called *pipe*) is the operator meaning *or*. Again, note the very important comma following the last column condition.

```{r eval=FALSE}
td<-td[td$Before == "Liquid" | td$Before == "Nasal" | td$Before == "Other Fricative" | td$Before == "S" | td$Before == "Stop",]
td$Before <-factor(td$Before)
```

As you did previously, you must run the second line of code to get rid of the empty `"Vowel"` level.

## Re-coding Variables

While it is possible to do *ad-hoc* re-codes in *R*, you must keep in mind that these re-codes will only exist in your *R* data frame, not in your saved tab-delimited-text file. Personally, I think it's both easier and more useful to use Microsoft *Excel* to create new columns in your tab-delimited-text file for every re-code or configuration of factors in a factor group (i.e., levels in a column) that you might need. That being said, there are definitely situations where *ad-hoc* recodes may be preferable.

If you want to change anything in your data frame you can generate an editable data frame in a popup window with the following function:

```{r eval=FALSE}
fix(td)
```

I don't recommend using this method. Like `file.choose()` and `choose.files()`, it introduces non-replicability because the changes you make using `fix()` are not recorded in your script file and therefore cannot be automatically replicated. A better practice for re-coding while maintaining replicability is to specify the cells in a column that include the specific values you want to change, and then to reassign a new value to those cells:

```{r}
td$After[td$After == "H"]<-"Consonant"
td$After <-factor(td$After)
```

The code above uses the `<-` operator to say that any cells in the column `After` that contain the value `"H"` should be changed to `"Consonant"` --- another value in the `After` column. Many studies of (t, d) deletion do not distinguish between pre-/h/ and other pre-consonantal contexts. The above re-code might be needed for comparing this (t, d) deletion data to other studies. Notice that there is no comma following `"H"` in the above code. This is because you are filtering a column; see how the filtering brackets `[ ]` come after the column specifier `$`. The comma is only used when filtering whole data frames because data frames can be filtered along two dimensions (e.g., rows and columns) and *R* needs to know which dimensions the filtering conditions apply to. When you filter just a column (or just a row), you don't need the comma because the filtering only occurs along one dimension (in that column, or in that row only). You also need to run the second `factor()` function to get rid of the now empty `"H"` level.

If you get an error message when trying to re-code using this method and your column contains words (rather than numbers) try first re-classifying (i.e., changing the type of) your original column to a *character* column: `td$After.New <- as.character(td$After.New)`, then proceeding with the above method.

The previous function sequence re-codes all `"H"` cells in the existing `After` column. If instead you wanted to create a new column with your re-code (so both possible coding options were available for later analyses), you could do so by creating a new column with the exact same values as `After` and then re-code that column. If you've been following along in *R*, your `After` column is already recoded. To go back to the original form of the data as it exists in the tab-delimited-text file, simply reload that text file and assign it to the object `td`. Of course, this resets the deletion of the tokens following a vowel, so you must do that again too. Luckily, you've written all of your functions in a script file (rather than directly into the console) so this is easy to do: just highlight the code and press the execution command.

```{r}
# Start with a fresh import of the (t, d) data into R
td <- read.delim("Data/deletiondata.txt")
# Convert each character column into a factor
td$Dep.Var <- factor(td$Dep.Var)
td$Stress <- factor(td$Stress)
td$Category <- factor(td$Category)
td$Morph.Type<- factor(td$Morph.Type)
td$Before <- factor(td$Before)
td$After <- factor(td$After)
td$Speaker <- factor(td$Speaker)
td$Sex <- factor(td$Sex)
td$Education <- factor(td$Education)
td$Job <- factor(td$Job)
td$Phoneme.Dep.Var <- factor(td$Phoneme.Dep.Var)
# Subset data to remove previous "Vowel" contexts
td <-td[td$Before != "Vowel",]
td$Before <-factor(td$Before)
#Re-code "H" to be "Consonant" in a new column
td$After.New<-td$After
td$After.New[td$After.New == "H"]<-"Consonant"
td$After.New <-factor(td$After.New)
```

The new column you create (`After.New`) is added at the end of the data frame. You can conceptualized this as the right edge of the data in an `Excel` spreadsheet. You can see this with the `summary()` or `str()` functions. The name of the new column you create doesn't really matter, but it cannot include any spaces.

```{r}
summary(td)
str(td)
```

## Centering Continuous Variables

Some variables, like year of birth, are not discrete but are continuous. Some statisticians advocate centering continuous variables before including them in certain tests or models.In the Regression Analysis section you'll learn when/if you need to center your variables.

*Centering* entails expressing each value of a continuous variable as that value's difference from the mean of all values of the variable. For example, the *td* data frame has a column for speaker year of birth: `YOB`. The mean of all the years of birth (after the pre-vowel tokens are removed) is `1969`. Centering this variable simply means expressing years of birth like 1952 and 1989, as 17 ($=1969-1952$) and -20 ($=1969-1989$).

```{r}
#Center YOB
td$Center.Age <-scale(td$YOB, scale = FALSE)
td$Center.Age <- as.numeric(td$Center.Age)
```

```{r, eval=FALSE}
td$Center.Age <-as.numeric(scale(td$YOB, scale = FALSE))
```

The `scale()` function centers the values in the column `YOB` and assigns those Centerd values to a new column called `Center.Age`. The option `scale = FALSE` indicates that the centered values remain in the original units (in this case years). If you change this option to `scale = TRUE`, the values are first divided by the standard deviation before being subtracted from the mean. This is needed if you are including multiple continuous variables in a model that are expressed using different units and vary along differing scales.

For example, imagine a study of variable word-initial voice onset time in which you want to look at the effect of following vowel backness and year of birth of the speaker. Each of these variables are continuous, but voice onset time is $\pm20$ ms around its mean, year of birth is $\pm45$ years around its mean, and F2 is $\pm300$ Hz around its mean. By first dividing each value of these three variables by the variable's standard deviation, you can account for both the differing units and differing scales of each. Even if you have one variable, here just `YOB`, it is okay to scale the values, but do *NOT* do this here. Leave `YOB` in years. This will make the interpretation of later statistical estimates a little easier.

After running your `scale()` function you must also run a function to tell *R* how to treat your new column `Center.Age.` *R* knows the column is filled with numbers, but *R* doesn't know if those numbers are continuous, if they are ordered in a specific way, or if they are factors with names expressed as digits. You use the function `as.numeric()` to tell *R* that the values are continuous numbers. This is very similar to what you did above with the function `factor()`, which tells *R* to consider whatever is inside the function to be a factor. Also, with `After.New` above, where the data structure is inherited from `After`, you used `factor()` to remove the remaining `H` level name. You did this by telling `R` to consider whatever was inside the `factor()` function as a factor, and, as part of that, `R` reads all the levels inside that column and chooses them as the factors. Here you are doing the same thing. You're telling `R` to look at the values inside `Center.Age` and consider them as being continuous numbers. You can do this as a secondary step after you create the column `Center.Age`, as shown in the first two rows. Or you can embed the `scale()` function inside the `as.numeric()` function, `as.numeric(scale())`, as shown in the last line.

## Dividing a Continuous Variable

There are other ways you can represent age. Instead of a continuous variable, you can categorize speakers as belonging to a "young","middle aged", or "old" age group. You might also group speakers based on decade of birth or as being born before or after some event --- whatever makes sense for your study or community.

How to divide speakers by age is something that should be informed by sociolinguistic theory, demographics, and your own understanding of your data. The birth years 1980 and 1945, used here, represent generational divides in Cape Breton that can be independently justified (Gardner 2013). Grouping speakers like this is very common, and not particularly difficult to do in *R*.

```{r}
# Create a 3-way Age Group
td$Age.Group[td$YOB >1979] <-"Young"
td$Age.Group[td$YOB >1944 & td$YOB <1980] <-"Middle"
td$Age.Group[td$YOB <1945] <-"Old"
```

First you will need a new column for your age group variable. Here, call it `Age.Group`.You use the assignment operator `<-` to fill all the cells in the new column `Age.Group` based on the values that are in the already existing `YOB` column. The first line says that for any rows in which `YOB` is greater than 1979, fill the empty cell in those same rows in the column `Age.Group` with the value `Young`. The second line does the same thing but includes two conditions: that `YOB` is greater than 1944 and that it is also less than 1980. For these rows, the value `Middle` is inserted in the `Age.Group` column. Even though the two conditions (`YOB > 1944`, `YOB < 1980`) refer to the same column, you need to fully specify each condition with both a column reference and a condition with an operator. So, for example, writing `td$Age.Group[td$YOB >1944 & <1970]` will not work. The third line instructs `R` to put `Old` in the `Age.Group` column for any row where `YOB` is less than 1945. Because this new column includes words, *R* will automatically categorize the column as `character` data. To rectify this, see the next section.

```{r}
class(td$Age.Group)
```

## Changing the Order of Levels

```{r}
td$Age.Group <-factor(td$Age.Group, levels = c("Young", "Middle", "Old"))
```

The code above does two things. First, it tells `R` that you want the new `Age.Group` column to be a column of factors, and second, it also tells `R` how you want those factors to be ordered. When `R` extracts the name of the factors of a column (based on the levels that are in that column) it orders the factors by name alphabetically. For example, the `Sex` column contains two levels: `M` and `F`. The first 500 tokens in your data frame might comes from males but `R` will still list the names of the factors in the column (which are based on those two levels) as `F` and then `M`, because `F` is closer to the start of the alphabet than `M`. If you run `summary(td)` you can see that the factor names listed in all of the factor columns are in alphabetical order. Sometimes this alphabetical ordering doesn't matter. Other times it is makes a big difference.

Any time factors are used in a statistical test or appear in a graph, the order of factor names is very important. For example, which factor is selected as the application value and which factor(s) are the non-application value(s) of a dependent variable is determined by factor name order. As for graphs, all kinds of layout parameters are set by the factor order of a variable. For example, if you left the `Age.Group` factor as it is, it would always list the `Age.Group` levels as `Middle`, `Old`, `Young`. On a graph like a bar graph it would arrange the bars for each age group alphabetically from left to right. This is not desirable. You will always want `Age.Group` ordered as either `Young`, `Middle`, `Old` or `Old`, `Middle`, `Young`. This is what the second part of the `factor()` command does. First it tells `R` to consider the values in the `Age.Group` to be factors, then it specifies that you want the factors (which get their names from the levels) to be ordered in certain way. You use `levels =` and the concatenating `c()` function to specify that you want the factors to get their names from the levels in the following order `"Young", "Middle", "Old"`, and thus also be ordered in that way.

This might seem confusing. Think about coins. Imagine you have a bag of change. Each coin in that bag is like a token in your column in the data frame. The levels of the column are just the different kinds of coins there are. You can root around in the bag and figure out what coins are in it without having to put the coins in any particular order. This is the "levels" of the coins. If you ask *R* what coins are in your bag, it will tell you there are "dimes", "nickels", "pennies", and "quarters". These levels are in alphabetical order, but only for a lack of a better way to tell you them. Telling you the levels doesn't imply any sort of ordering of the coins. Making the coin bag into a factor column is like putting the coins into a change tray, like the change trays in cash registers. Coins inside of a change tray go from being unstructured to being organized based on a structure. This makes them factors. In a cash tray each coin is grouped with other coins just like it. Each slot in the drawer also has a name. *R* just automatically gives the slots the same name as the coins (e.g. levels) that are in it. The order of the slots from right to left is also by default alphabetical based on the name of each slot. So, coin (= level), slot name (= factor name) and slot order (= factor order) are three independent parameters. The function `td$Age.Group <-factor(td$Age.Group, levels = c("Young", "Middle", "Old"))` is basically saying take all the coins out of the cash drawer, then put them back in the drawer in in a specific order, with `Young` going in the first slot. The slots then take the names of the coins that go into them.

## Reversing the Order of Levels

To reverse the order of levels you can embed the `rev()` function inside your `factor()` function

```{r}
levels(td$Age.Group)
td$Age.Group <-factor(td$Age.Group, levels = rev(levels(td$Age.Group)))
levels(td$Age.Group)
```

## Combining Columns

It is often useful to combine two columns, or factor groups, into one. For example, it might be useful to have a way of grouping tokens not by `Age.Group` or `Sex`, but instead by the combination of `Age.Group` and `Sex`. While it is not difficult to test the potential interaction of these two factor groups in statistical tests in *R*, for specifically generating summary statistics it is much easier to examine the combination of `Age.Group` and `Sex` (or any two columns) by first creating a new column combining them.

Combining columns is done using the function `paste()`, which you embed inside of the `factor()` function so that the resulting column will be a column of factors. Inside `paste()` you list the two columns you want to combine (you could list more) and then tell *R* how to separate the values from each of the columns. Here the code tells *R* to put an underscore \*\_\* between the values for `Age.Group` and `Sex`, resulting in new values like `Old_M` and `Middle_F`. The new column will be called `Age_Sex`. If we want to order these values in any particular way, we can do that with the `level=` option in `factor()`

```{r}
# Combine Columns 
td$Age_Sex <-factor(paste(td$Age.Group, td$Sex, sep ="_"), levels = c("Young_F", "Middle_F", "Old_F", "Young_M", "Middle_M", "Old_M"))
levels(td$Age_Sex)
# Reorder factor levels
td$Age_Sex <-factor(td$Age_Sex, levels = c("Young_F", "Young_M", "Middle_F", "Middle_M", "Old_F", "Old_M"))
levels(td$Age_Sex)
```

## Splitting Columns

You may have noticed that the data frame `td` has one column that is actually two variables. The column `Phoneme.Dep.Var` combines both the underlying phoneme of the token, either `t` (t) or `d` (d), with a more descriptive coding of the dependent variable. In the dialect where this data comes from (t) and (d) can be realized in up to nine different ways, only one of which is `Deletion`. In your analysis you might want to consider if deletion is more likely if the underlying phoneme is (t) or (d). In order to do this you must break `Phoneme` away from the more elaborate `Dep.Var` coding. To do this, you will use a function that is beyond *R*'s base functionality and part of the `dplyr` package. First you load the `dplyr` package from your library using `library()`, then you use the function `mutate()` to tell *R* how to break up the column. The `dplyr` package is very powerful. We will look at additional uses as this guide progresses.

To be honest, splitting columns is an operation that is much simpler and usually faster to do using *Excel*, or another spreadsheet program. I never use *R* to split columns because, while the `mutate()` function itself is not tricky, figuring out the exact sequence of `regular expressions` I need to split my columns is challenging. If you absolutely must split columns in *R*, below are instructions. Keep in mind that this method will only work for columns with predictable structures, like `Phoneme.Dep.Var`.

The values in the column `Phoneme.Dep.Var` are predictable, in other words, they all follow the same pattern. You can exploit this regularity to tell *R* exactly where to break the `Phoneme.Dep.Var` values into two. If you execute the command `levels(td$Phoneme.Dep.Var)` you can very easily see the pattern.

```{r}
levels(td$Phoneme.Dep.Var)
```

The first part of every value is either `t` or `d`, then there are two hyphens, then a word describing the realization of (t) or (d). If you split `Phoneme.Dep.Var` at the hyphens you'll be left with two values: one that is either `t` or `d`, and another that describes the realization of (t) or (d). So, for the new `Phoneme` column you want the one character before the hyphens from `Phoneme.Dep.Var`, and for the new `Dep.Var.Full` column, you want all the characters --- however many there are -- that come after the two hyphens.

```{r}
# Break Phoneme.Dep.Var into two columns
library(dplyr)
td <-mutate(td, Phoneme = sub("^(.)(--.*)$", "\\1", Phoneme.Dep.Var), Dep.Var.Full = sub("^(.--)(.*)$", "\\2", Phoneme.Dep.Var), Phoneme.Dep.Var = NULL)
td$Dep.Var.Full <-factor(td$Dep.Var.Full)
td$Phoneme <-factor(td$Phoneme)
```

::: {style="color: #009fe3; background: #d8f0fa;"} <strong> Note: </strong> The procedure here is somewhat complicated. I always have to double-check how these complicated procedures work. Either by looking up the functions or checking my old script files. You can look up how a function like `mutate()` works by placing a question mark before the function in the console window, e.g. \texttt{?mutate()}. :::

Above, inside the `mutate()` function, first you specify the data frame object you want to mutate (here `td`), and then how to mutate it. The mutations include creating a new column called `Phoneme` and then telling *R* what do put in it, creating a new column called `Dep.Var.Full` and then telling *R* what to put in it, and then taking the `Phoneme.Dep.Var` column and making it equal `NULL` --- in other words, deleting it. For the `Phoneme` and `Dep.Var.Full` columns you specify what values to insert in each cell using the `sub()` function, which returns a "sub" or divided section of a value within some cell. The `sub()` function's first argument is a pattern of *regular expressions* to search for, the second is a character string to replace the pattern with, and the third is the column in which to search for the pattern.

::: {style="color: #009fe3; background: #d8f0fa;"} <strong> Note: </strong> I don't have *R*'s regular expressions memorized; I always have to look them up [here](https://stat.ethz.ch/R-manual/R-devel/library/base/html/regex.html) :::

For the \texttt{sub()} functions meant to create values for `Phoneme` and for `Dep.Var.Full` you tell *R* to search `Phoneme.Dep.Var` for the pattern `"^.--.*$"`. This series of regular expressions describes the following pattern: a text string beginning with one single character, followed by two hyphens, and then any number of characters. The quotation marks `" "` indicate a text string. The `^` and `$` indicate the beginning and end of a text string, respectively.[^2] The period `.` indicates a single character and the asterisk`*` indicates zero or more of whatever comes before that asterisk. So `.*` means any one or more characters. The two hyphens `--` are just two hyphens. The parentheses in the regular expressions relate to the second substitution element. In the `sub()` function responsible for creating values for the new `Phoneme` column, you break the values that match the regular expression pattern into two parts: the one character before the two hyphens `(.)` and then everything after it `(--.*)`; then you tell *R* to substitute (or rather place) the first of those two elements `\\1` as text `" "` in the new column. In the `sub()` function responsible for creating the values for the new `Dep.Var.Full` column, you break the values that match the regular expression pattern into two parts: the two hyphens and the one character that comes before them `(.--)` and then the one or more characters that come after the hyphens `(.*)`; then tell *R* to to substitute (or rather place) the second of those elements `\\2` as text `" "` in the new column.

[^2]: You use `$` in other places for specifying columns within data frames, but here it's inside quotation marks and serving a different function.

The last two lines simply make these two new columns into factor columns.

## Partitioning Data Frames

Many times in my own work I have only wanted to work in *R* with a subset of my full dataset. For example, I frequently want to run separate regression analyses on data from old speakers, middle age speakers, and young speakers. Other times I've had large datasets that combine multiple corpora and have wanted to run tests on data from just one corpus. Being able to partition (subset) my data frame has therefore been very useful.

There are two main ways to partition your data. One method involves using the filtering functionality of *R* detailed above. For example, the first line code below represents the `td` data from `young` speakers only. The second line of codes assigns that subset of `td` to a completely new data frame.

```{r eval=FALSE}
# Subset of td where  Age.Group only equals Young 
td[td$Age.Group == "Young",]
```

```{r}
# Create td.young which equals subset of td where Age. Group only equals Young
td.young <- td[td$Age.Group == "Young",]
```

In your tests you can use the filtered version of `td` or you can use the new data frame `td.young`. I recommend using the new data frame if you are using any centered continuous variables. This is because centered continuous variables are centered around the mean of the values in the column that is centered. If you partition the data, that mean will be different because the range of values within the the centered column are now different. So, if you partition your data, especially by age, you should re-center your continuous variables.

The second way to partition your data is using the `subset()` function.

```{r}
# Create three partitions based on Age.Group
td.young <-subset(td, Age.Group == "Young")
td.middle <-subset(td, Age.Group == "Middle")
td.old <-subset(td, Age.Group == "Old")
# Re-Center Center.Age
td.young$Center.Age <- scale(td.young$YOB, scale = FALSE)
td.middle$Center.Age <- scale(td.middle$YOB, scale = FALSE)
td.old$Center.Age <- scale(td.old$YOB, scale = FALSE)
```

The usefulness of `subset()` is when you want to partition your data frame based on several factors. For example, compare the filtering versus `subset()` methods when partitioning `td` for just middle-age, blue-collar men. Using \texttt{subset()} saves you from having to type `td$` multiple times, and you don't need the final `,`.

```{r}
# Subset of td where Age.Group is Middle, Sex is M, and Job is Blue
td.midmenblue  <- td[td$Age.Group == "Middle" & td$Sex == "M" & td$Job == "Blue",]
# Subset of td where Age.Group is Middle, Sex is M, and Job is Blue
td.midmenblue <-subset(td, Age.Group == "Middle" & Sex == "M" & Job == "Blue") 
```

When you subset your data frame, using either method, and assign it to a new data frame, your new data frame inherits the structure of your old data frame. This means that there will be lots of columns that list empty levels. If you execute `summary(td.midmenblue)}` you'll see see that `Job` still lists `Service`, `Student`, and `White` as factors with 0 tokens each. To remove these empty levels you could use the `factor()` function on each column with empty levels (as you did above), or you can use the function `droplevels()` to tell *R* to drop any empty levels from each column in the data frame. You need to make sure to also assign the dropped levels data frame to the original data frame, as shown below.

```{r}
summary(td.midmenblue)
# Drop empty levels across dataset
td.midmenblue <- droplevels(td.midmenblue)
summary(td.midmenblue)
```

## Interim Summary

Below is the full code for loading the data file and then re-coding it. As you progress through the next sections, if for any reason you have a problem, it may be useful to recreate the *R* object `td` from scratch. Going forward in these instructions, the `td` object will be the object as it exists at the end of this code.

```{r echo=FALSE}
td <- read.delim("Data/deletiondata.txt")
```

```{r eval=FALSE}
# Read in token file
td <-read.delim("https://www.dropbox.com/s/jxlfuogea3lx2pu/deletiondata.txt?dl=1")
```

```{r}
# Subset data to remove previous "Vowel" contexts
td <- td[td$Before != "Vowel",]
td$Before <-factor(td$Before)
# Re-code "H" to be "Consonant" in a new column
td$After.New <- td$After
td$After.New[td$After.New == "H"] <- "Consonant"
td$After.New <- factor(td$After.New)
# Center Year of Birth
td$Center.Age <- as.numeric(scale(td$YOB, scale = FALSE))
# Create Age.Group
td$Age.Group[td$YOB >1979] <- "Young"
td$Age.Group[td$YOB >1944 & td$YOB <1980] <- "Middle"
td$Age.Group[td$YOB <1945] <- "Old"
td$Age.Group <-factor(td$Age.Group, levels = c("Young", "Middle", "Old"))
# Combine Age and Sex
td$Age_Sex <- factor(paste(td$Age.Group, td$Sex, sep ="_"))
# Break Phoneme.Dep.Var into two columns
library(dplyr)
td <- mutate(td, Phoneme = sub("^(.)(--.*)$", "\\1", Phoneme.Dep.Var), Dep.Var.Full = sub("^(.--)(.*)$", "\\2", Phoneme.Dep.Var), Phoneme.Dep.Var = NULL)
td$Phoneme <-factor(td$Phoneme)
td$Dep.Var.Full <- factor(td$Dep.Var.Full)	
# Create three partitions based on Age.Group
td.young <- droplevels(subset(td, Age.Group == "Young"))
td.middle <- droplevels(subset(td, Age.Group == "Middle"))
td.old <- droplevels(subset(td, Age.Group == "Old"))
# Re-center Center.Age
td.young$Center.Age <- scale(td.young$YOB, scale = FALSE)
td.middle$Center.Age <- scale(td.middle$YOB, scale = FALSE)
```

## Doing It All Again, But `tidy`

The package `dplyr` is part of a larger "universe" of *R* packages called `tidyverse`. This collection of packages is specifically focused on data science and offers some shortcuts that are useful to learn. The packages that make up the `tidyverse` are `dplyr`, `ggplot2`, `purr`, `tibble`, `tidyr`, `stingr`, `readr`, and `forcats`, among others. Throughout this guide I try to use the most basic *R* syntax for accomplishing a task. This way you learn how *R* works. I will also show how to complete the same task using packages from the `tidyverse`. Using the `tidyverse` methods is usually optional --- though once you get the hang of it, you might always use the `tidyverse` methods.

```{r eval=FALSE}
# Install the tidyverse package
install.packages("tidyverse")
```

```{r message=FALSE,warning=FALSE }
# Load the tidyverse package
library(tidyverse)
```

```{r}
# List the packages loaded by the tidyverse package
tidyverse_packages()
```

Before we get started with the `tidyverse`, there are two important new things to learn about. The first is the pipe operator `%>%` and the second is the the alternative to a *data frame* called a *tibble*.

### The Pipe %\>%

The pipe operator `%>%`[^3] is introduced by the `magrittr` package[^4] and it is extremely useful. The pipe operator passes the output of a function to the first argument of the next function, which mean you can chain several steps together.

[^3]: Not to be confused with the operator `|`, which means "or" and whose symbol is also called pipe

[^4]: Loading `dplyr` will also let you use it

For example, lets find the mean year of birth in our data. We already know that when the pre-vowel contexts are removed, the mean year of birth is 1969.

```{r}
# Find mean YOB using mean() function
mean(td$YOB)
# Find the mean YOB by piping the td data to the mean() function
td$YOB %>% mean()
```

The functionality of `%>%` might seem trivial at this point; however, when you need to perform multiple tasks sequentially, it saves a lot of time and space when writing your code.

### Tibbles

A *tibble* is an updated version of a *data frame*. *Tibbles* keep the features that have stood the test of time, and drop the features that used to be convenient but are now frustrating (i.e. converting character vectors to factors). For our purposes, the difference between the two is negligible, but you should be aware that *tibbles* look a bit different from *data frames*.

```{r,attr.output='style="max-height: 500px;"', R.options = list(width = 1000)}
as.data.frame(td)
```

```{r,attr.output='style="max-height: 500px;"', R.options = list(width = 1000)}
as_tibble(td)
```

Notice that the *tibble* lists the dimensions of the tibble at the top, as well as the class of each of the columns. It also only displays the first 10 rows. You'll also notice that the row numbers have reset when we converted `td` to a *tibble*. If we want to view the entire tibble, we can use the `print()` function and specify the `n=` plus the number of rows we want to see, including all rows (`n=Inf`). You can see below how the pipe operator makes doing this pretty easy.

```{r, eval=FALSE}
# Embedding functions
print(as_tibble(td), n=20)
```

The above produces the same as the following:

```{r,attr.output='style="max-height: 500px;"', R.options = list(width = 1000)}
# Using %>% to pass the results from the first function to the second function
as_tibble(td)%>%
  print(n=20)
```

### Getting a `glimpse()`

Another useful addition to data exploration is the `glimpse()` function from the `pilllar` package and re-exported by `dplyr`. The `glipmpse()` function is like a cross between `print()` (which shows the data) and `str()` (which shows the structure of the data). I use `glimpse()` almost as frequently as I use `summary()`. In fact, if you have very wide data, i.e., with lots of columns, `glimpse()` may prove more useful than `summary()` for getting a quick snapshot of your data. `glimpse()` shows the number of rows, the number of columns, the name of each column, its class, and however many values in each column as will fit horizontally in the console.

```{r}
glimpse(td)
```

### Manipulating data with `dplyr`

The `dplyr` package is great for manipulating data in a data frame/tibble. Some common things that `diplyr` can do include:

| Function      | Description                               |
|---------------|-------------------------------------------|
| `mutate()`    | add new variables or modify existing ones |
| `select()`    | select variables                          |
| `filter()`    | filter                                    |
| `summarize()` | summarize/reduce                          |
| `arrange()`   | sort                                      |
| `group_by()`  | group                                     |
| `rename()`    | rename columns                            |

Lets redo all our data manipulation of `td` but with `dplyr` and its pipe `%>%` operator

```{r echo=FALSE}
td <- read.delim("Data/deletiondata.txt")
```

```{r eval=FALSE}
# Read in token file
td <- read.delim("https://www.dropbox.com/s/jxlfuogea3lx2pu/deletiondata.txt?dl=1")
```

```{r}
# Subset data to remove previous 'Vowel' contexts
td <- td %>% # pass td to next function
      filter(Before != "Vowel") # filter td to include everything that is not "Vowel" in the column Before
# Re-code 'H' to be 'Consonant' in a new column
td <- td %>% # pass td to next function
      mutate(After.New = recode(After, "H" = "Consonant")) # create a new column called After.New that equals a re-code of After in which H is re-coded as Consonant
# Center Year of Birth
td <- td %>% # pass td to next function
     mutate(Center.Age = as.numeric(scale(YOB, scale = FALSE))) # create a new column called Center.Age equal to the YOB column but scaled
# Create Age.Group
td <- td %>% # pass td to next function
      mutate(Age.Group = cut(YOB, breaks = c(-Inf, 1944, 1979, Inf), 
                                  labels = c("Old", "Middle", "Young"))) # cut the YOB into discrete categories. 
```

Before we continue, a note about the `cut()` function. The `breaks=` option is a concatenated list of boundaries. It should start and end with `-Inf` and `Inf` (negative and positive infinity) as these will be the lower and upper bounds. The other values are the boundaries or cut-off points. By default `cut()` has the setting `right=TRUE`, which means the boundary values will be are considered the last value in a group (e.g., rightmost value). Above, this means `1944` will be the highest value in the `Old` category and `1979` will the the highest value in the `Middle` category. To reverse this you can add the option `right=FALSE` in which case 1944 would be the lowest value in the `Middle` category (e.g. leftmost value) and 1979 would be the lowest value in the `Young` category.

Let's continue.

```{r, tidy=FALSE}
# Combine Age and Sex

td <-td %>% # pass td to next function
     unite("Age_Sex", Age.Group:Sex, sep= "_", remove = FALSE) # using the unite() function from the tidyr package, if remove=TRUE the original Age.Group and Sex columns will be deleted
    
# Break Phoneme.Dep.Var into two columns
td <-td %>% # pass td to next function
 mutate(Phoneme = sub("^(.)(--.*)$", "\\1", 
        Phoneme.Dep.Var), 
        Dep.Var.Full = sub("^(.--)(.*)$", "\\2", 
        Phoneme.Dep.Var), 
        Phoneme.Dep.Var = NULL) # Same as before, but with td passed to mutate() by the %>% operator

```

At this point we have done everything except partition the data and re-center YOB in the partitioned data frames. You may ask, "How is this better?". Well, the answer is that because all these modifications feed into one another, we can actually include them all together in one serialized operation. Behold!

All of the above code can be simplified as follows:

```{r echo=FALSE}
td <- read.delim("Data/deletiondata.txt")
```

```{r eval=FALSE}
# Read in token file
td <- read.delim("https://www.dropbox.com/s/jxlfuogea3lx2pu/deletiondata.txt?dl=1")
```

```{r, tidy=FALSE}
# Subset data to remove previous 'Vowel' contexts, then modify several columns
td <- td %>%
      filter(Before != "Vowel")%>%
      mutate(After.New = recode(After, "H" = "Consonant"),  
             Center.Age = as.numeric(scale(YOB, scale = FALSE)),
             Age.Group = cut(YOB, breaks = c(-Inf, 1944, 1979, Inf), 
                                  labels = c("Old", "Middle", "Young")),
             Phoneme = sub("^(.)(--.*)$", "\\1", Phoneme.Dep.Var),
             Dep.Var.Full = sub("^(.--)(.*)$", "\\2", Phoneme.Dep.Var),
             Phoneme.Dep.Var = NULL)%>%
            mutate_if(is.character, as.factor)
  
```

Now, doesn't the above look so much cleaner and easier to follow?

To partition the data we still need separate functions.

```{r}
td.young <- td %>% 
            filter(Age.Group == "Young")%>%
            mutate(Center.Age = as.numeric(scale(YOB, scale = FALSE)))

td.middle <- td %>% 
             filter(Age.Group == "Middle")%>%
             mutate(Center.Age = as.numeric(scale(YOB, scale = FALSE)))

td.old <- td %>% 
          filter(Age.Group == "Old")%>%
          mutate(Center.Age = as.numeric(scale(YOB, scale = FALSE)))
```
